{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.models.optical_flow.raft import ResidualBlock\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.618590Z",
     "start_time": "2024-06-12T19:34:25.271959Z"
    }
   },
   "id": "685462a85f2ae1e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.622838Z",
     "start_time": "2024-06-12T19:34:31.619545Z"
    }
   },
   "id": "8fb89e7978c49f98",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Network definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47bdd2924b375a67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NetA1(nn.Module):\n",
    "    def __init__(self, num_classes: int, freeze: bool = False):\n",
    "        super(NetA1, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=2)\n",
    "        self.flatten = nn.Flatten(start_dim=-3)\n",
    "        self.linear1 = nn.Linear(676, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        if freeze:\n",
    "            for param in self.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.633434Z",
     "start_time": "2024-06-12T19:34:31.625366Z"
    }
   },
   "id": "8e067a677d103ee6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NetA2(nn.Module):\n",
    "    def __init__(self, num_classes: int, freeze: bool = False):\n",
    "        super(NetA2, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=6, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten(start_dim=-5)\n",
    "        self.linear1 = nn.Linear(150, 200)\n",
    "        self.linear2 = nn.Linear(200, 100)\n",
    "        self.linear3 = nn.Linear(100, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        if freeze:\n",
    "            for param in self.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.pool1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.645917Z",
     "start_time": "2024-06-12T19:34:31.636532Z"
    }
   },
   "id": "4f398a6ac2c01f29",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Network initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99360d229c0dbc75"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 1, 3, 3])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialization_weights = torch.tensor([\n",
    "    [[[1, 0, 1], [0, 1, 0], [1, 0, 1]]],\n",
    "    [[[1, 1, 0], [0, 0, 1], [1, 1, 0]]],\n",
    "    [[[0, 1, 1], [1, 0, 0], [0, 1, 1]]],\n",
    "    [[[0, 1, 0], [1, 1, 0], [0, 1, 0]]]\n",
    "            ], dtype=torch.float32)\n",
    "\n",
    "initialization_biases = torch.tensor([0,0,0,0], dtype=torch.float32)\n",
    "initialization_weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.672715Z",
     "start_time": "2024-06-12T19:34:31.647927Z"
    }
   },
   "id": "3e5ae64e8c459822",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_A1_HF: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 0., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [0., 1., 0.]]]])), ('conv1.bias', tensor([0., 0., 0., 0.])), ('linear1.weight', tensor([[-0.0263, -0.0308,  0.0384,  ...,  0.0129, -0.0315,  0.0162],\n",
      "        [-0.0317,  0.0038, -0.0353,  ...,  0.0243,  0.0187, -0.0363],\n",
      "        [ 0.0232,  0.0346, -0.0316,  ...,  0.0108, -0.0291, -0.0165],\n",
      "        ...,\n",
      "        [-0.0332, -0.0109,  0.0028,  ..., -0.0177,  0.0285, -0.0358],\n",
      "        [-0.0114, -0.0106, -0.0180,  ..., -0.0125, -0.0106, -0.0105],\n",
      "        [ 0.0046, -0.0014, -0.0378,  ..., -0.0194,  0.0318,  0.0112]])), ('linear1.bias', tensor([ 0.0020, -0.0011, -0.0044, -0.0213,  0.0053,  0.0065,  0.0043, -0.0234,\n",
      "         0.0307, -0.0009]))])\n",
      "Net_A1_HT: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 0., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [0., 1., 0.]]]])), ('conv1.bias', tensor([0., 0., 0., 0.])), ('linear1.weight', tensor([[-0.0263, -0.0308,  0.0384,  ...,  0.0129, -0.0315,  0.0162],\n",
      "        [-0.0317,  0.0038, -0.0353,  ...,  0.0243,  0.0187, -0.0363],\n",
      "        [ 0.0232,  0.0346, -0.0316,  ...,  0.0108, -0.0291, -0.0165],\n",
      "        ...,\n",
      "        [-0.0332, -0.0109,  0.0028,  ..., -0.0177,  0.0285, -0.0358],\n",
      "        [-0.0114, -0.0106, -0.0180,  ..., -0.0125, -0.0106, -0.0105],\n",
      "        [ 0.0046, -0.0014, -0.0378,  ..., -0.0194,  0.0318,  0.0112]])), ('linear1.bias', tensor([ 0.0020, -0.0011, -0.0044, -0.0213,  0.0053,  0.0065,  0.0043, -0.0234,\n",
      "         0.0307, -0.0009]))])\n",
      "Net_A1_DT: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[-0.2883,  0.1564,  0.1609],\n",
      "          [-0.0444, -0.0949, -0.3182],\n",
      "          [ 0.2915,  0.3080,  0.2105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1010,  0.2522,  0.2758],\n",
      "          [ 0.2323,  0.2154,  0.2896],\n",
      "          [-0.2110, -0.0941, -0.2463]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2065,  0.2438, -0.1999],\n",
      "          [ 0.0054,  0.0993, -0.0013],\n",
      "          [-0.0640,  0.0031,  0.0364]]],\n",
      "\n",
      "\n",
      "        [[[-0.1630,  0.0651, -0.3326],\n",
      "          [ 0.1536,  0.0603,  0.2092],\n",
      "          [-0.3016,  0.1574,  0.1269]]]])), ('conv1.bias', tensor([ 0.1892, -0.2638,  0.0942, -0.1126])), ('linear1.weight', tensor([[-0.0263, -0.0308,  0.0384,  ...,  0.0129, -0.0315,  0.0162],\n",
      "        [-0.0317,  0.0038, -0.0353,  ...,  0.0243,  0.0187, -0.0363],\n",
      "        [ 0.0232,  0.0346, -0.0316,  ...,  0.0108, -0.0291, -0.0165],\n",
      "        ...,\n",
      "        [-0.0332, -0.0109,  0.0028,  ..., -0.0177,  0.0285, -0.0358],\n",
      "        [-0.0114, -0.0106, -0.0180,  ..., -0.0125, -0.0106, -0.0105],\n",
      "        [ 0.0046, -0.0014, -0.0378,  ..., -0.0194,  0.0318,  0.0112]])), ('linear1.bias', tensor([ 0.0020, -0.0011, -0.0044, -0.0213,  0.0053,  0.0065,  0.0043, -0.0234,\n",
      "         0.0307, -0.0009]))])\n"
     ]
    }
   ],
   "source": [
    "net_a1_hf = NetA1(10, True)\n",
    "net_a1_ht = NetA1(10)\n",
    "net_a1_dt = NetA1(10)\n",
    "\n",
    "#set conv1 initialization\n",
    "net_a1_hf.conv1.weight = nn.Parameter(initialization_weights)\n",
    "net_a1_hf.conv1.bias = nn.Parameter(initialization_biases)\n",
    "\n",
    "# set same weights and bias to each layer of each network (except for cov1 of net_a1_dt)\n",
    "net_a1_ht.load_state_dict(net_a1_hf.state_dict())\n",
    "net_a1_dt.linear1.load_state_dict(net_a1_hf.linear1.state_dict())\n",
    "\n",
    "#save weights and bias of nat_a1_h* and net_a1_dt\n",
    "torch.save({'initialization': net_a1_hf.state_dict()}, 'NetA1H+_init.pt')\n",
    "torch.save({'initialization': net_a1_dt.state_dict()}, 'NetA1DT_init.pt')\n",
    "\n",
    "\n",
    "# print weights and bias\n",
    "print(\"Net_A1_HF: \\n \\t\", net_a1_hf.state_dict())\n",
    "print(\"Net_A1_HT: \\n \\t\", net_a1_ht.state_dict())\n",
    "print(\"Net_A1_DT: \\n \\t\", net_a1_dt.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:34:31.851709Z",
     "start_time": "2024-06-12T19:34:31.674729Z"
    }
   },
   "id": "ed80d43768e0ffd6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_A1_HF: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 0., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [0., 1., 0.]]]])), ('conv1.bias', tensor([0., 0., 0., 0.])), ('conv2.weight', tensor([[[[ 0.0277,  0.1149, -0.1208],\n",
      "          [ 0.1161,  0.1605, -0.0957],\n",
      "          [-0.1079, -0.1183, -0.0668]],\n",
      "\n",
      "         [[-0.1547, -0.0691, -0.1027],\n",
      "          [-0.0794, -0.0236,  0.0004],\n",
      "          [-0.0838,  0.0406, -0.0066]],\n",
      "\n",
      "         [[ 0.0825, -0.1004,  0.0103],\n",
      "          [ 0.0283,  0.0741, -0.0702],\n",
      "          [-0.0884,  0.0566, -0.1151]],\n",
      "\n",
      "         [[ 0.0678,  0.1228, -0.0446],\n",
      "          [ 0.1102,  0.0567, -0.1177],\n",
      "          [-0.0948,  0.1466,  0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0481, -0.1236, -0.0548],\n",
      "          [-0.1211,  0.0455, -0.0900],\n",
      "          [-0.0881, -0.0630,  0.0127]],\n",
      "\n",
      "         [[-0.0302, -0.0815, -0.0060],\n",
      "          [-0.1386, -0.0463,  0.0019],\n",
      "          [-0.0203, -0.0756,  0.0394]],\n",
      "\n",
      "         [[ 0.0220,  0.0737,  0.0375],\n",
      "          [ 0.1448, -0.0480,  0.0053],\n",
      "          [-0.0264, -0.1254,  0.0408]],\n",
      "\n",
      "         [[-0.1433, -0.0717, -0.1519],\n",
      "          [-0.0284,  0.0483,  0.1254],\n",
      "          [ 0.1048, -0.1471, -0.0192]]],\n",
      "\n",
      "\n",
      "        [[[-0.1214, -0.0114, -0.0650],\n",
      "          [ 0.0441,  0.1437, -0.0815],\n",
      "          [-0.1046,  0.1386, -0.0093]],\n",
      "\n",
      "         [[-0.1239,  0.0977,  0.1428],\n",
      "          [-0.0667,  0.0277, -0.1622],\n",
      "          [-0.0084, -0.1623, -0.0426]],\n",
      "\n",
      "         [[-0.0744, -0.0416, -0.0755],\n",
      "          [ 0.1014, -0.0479,  0.1453],\n",
      "          [ 0.1127,  0.0843,  0.1025]],\n",
      "\n",
      "         [[-0.1527,  0.0352,  0.0479],\n",
      "          [-0.0681, -0.1173, -0.1619],\n",
      "          [ 0.1134, -0.1410,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1035,  0.1176, -0.1514],\n",
      "          [-0.0786, -0.0893, -0.0645],\n",
      "          [ 0.0692,  0.0216,  0.0929]],\n",
      "\n",
      "         [[ 0.0940,  0.0771, -0.0682],\n",
      "          [-0.0937,  0.1657,  0.0603],\n",
      "          [-0.0226, -0.0135, -0.0929]],\n",
      "\n",
      "         [[ 0.0138, -0.1619,  0.0119],\n",
      "          [ 0.0873,  0.0704, -0.1510],\n",
      "          [ 0.1643, -0.0898, -0.1235]],\n",
      "\n",
      "         [[-0.0768,  0.1207, -0.0881],\n",
      "          [-0.0107, -0.1406,  0.0444],\n",
      "          [-0.0925, -0.1311,  0.0439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1248,  0.0391,  0.1382],\n",
      "          [-0.1300, -0.0065, -0.1247],\n",
      "          [ 0.0092,  0.0483,  0.0728]],\n",
      "\n",
      "         [[-0.0111, -0.1385, -0.0405],\n",
      "          [ 0.0897, -0.1337,  0.0845],\n",
      "          [ 0.0412,  0.1241,  0.1158]],\n",
      "\n",
      "         [[-0.0636, -0.1513, -0.1154],\n",
      "          [ 0.0560, -0.0266,  0.1168],\n",
      "          [-0.0036, -0.1158, -0.0499]],\n",
      "\n",
      "         [[-0.0608,  0.0503, -0.0282],\n",
      "          [ 0.1367, -0.0551, -0.0871],\n",
      "          [-0.0443,  0.1156, -0.0237]]],\n",
      "\n",
      "\n",
      "        [[[-0.0578,  0.1307,  0.1498],\n",
      "          [ 0.1168,  0.1255, -0.0361],\n",
      "          [ 0.0610,  0.0237,  0.0126]],\n",
      "\n",
      "         [[-0.1344,  0.0685, -0.1344],\n",
      "          [ 0.1060,  0.1278,  0.1221],\n",
      "          [-0.0153, -0.1446, -0.1478]],\n",
      "\n",
      "         [[ 0.1608,  0.0608, -0.1501],\n",
      "          [ 0.0874, -0.0374, -0.1175],\n",
      "          [ 0.1032,  0.1281,  0.0354]],\n",
      "\n",
      "         [[-0.0255, -0.0660, -0.1522],\n",
      "          [ 0.1521, -0.0384,  0.1535],\n",
      "          [ 0.0805,  0.1001,  0.0620]]]])), ('conv2.bias', tensor([ 0.1004,  0.0124, -0.1523, -0.0778, -0.1434,  0.1143])), ('linear1.weight', tensor([[-0.0275,  0.0443,  0.0005,  ..., -0.0383,  0.0138, -0.0651],\n",
      "        [ 0.0233, -0.0665, -0.0592,  ...,  0.0673, -0.0275, -0.0332],\n",
      "        [ 0.0632,  0.0485, -0.0634,  ..., -0.0548,  0.0289, -0.0629],\n",
      "        ...,\n",
      "        [ 0.0778,  0.0472, -0.0498,  ..., -0.0364,  0.0123,  0.0035],\n",
      "        [-0.0745,  0.0345, -0.0013,  ...,  0.0689, -0.0481, -0.0798],\n",
      "        [ 0.0390, -0.0745, -0.0550,  ...,  0.0629,  0.0341, -0.0304]])), ('linear1.bias', tensor([-0.0615, -0.0117,  0.0083, -0.0375, -0.0580,  0.0219, -0.0233, -0.0567,\n",
      "        -0.0102, -0.0006,  0.0032,  0.0647, -0.0771,  0.0072,  0.0516,  0.0269,\n",
      "        -0.0402, -0.0172, -0.0466, -0.0546, -0.0268, -0.0388, -0.0094,  0.0358,\n",
      "        -0.0276,  0.0461,  0.0257,  0.0505,  0.0458,  0.0628,  0.0648, -0.0669,\n",
      "        -0.0587,  0.0765, -0.0807, -0.0726, -0.0490, -0.0641,  0.0527, -0.0764,\n",
      "         0.0208,  0.0653, -0.0799,  0.0142,  0.0747,  0.0797, -0.0318, -0.0208,\n",
      "        -0.0451,  0.0541,  0.0603,  0.0626,  0.0525, -0.0668, -0.0755, -0.0148,\n",
      "        -0.0544, -0.0346, -0.0522, -0.0331, -0.0085, -0.0209,  0.0567,  0.0244,\n",
      "        -0.0542, -0.0250, -0.0556,  0.0445,  0.0544, -0.0008,  0.0119,  0.0752,\n",
      "         0.0406,  0.0255, -0.0497,  0.0692,  0.0801, -0.0405, -0.0339,  0.0262,\n",
      "        -0.0640, -0.0108,  0.0157,  0.0221,  0.0672,  0.0356, -0.0687, -0.0281,\n",
      "         0.0106, -0.0533,  0.0336,  0.0470, -0.0289, -0.0344,  0.0392,  0.0199,\n",
      "        -0.0141, -0.0644,  0.0807, -0.0422,  0.0643,  0.0413, -0.0112,  0.0028,\n",
      "         0.0056,  0.0735, -0.0429,  0.0387, -0.0054, -0.0104,  0.0050,  0.0644,\n",
      "        -0.0451, -0.0361, -0.0785,  0.0084,  0.0092, -0.0086, -0.0058, -0.0072,\n",
      "         0.0490,  0.0569, -0.0599, -0.0766, -0.0016,  0.0697, -0.0089,  0.0085,\n",
      "        -0.0793,  0.0716, -0.0429, -0.0049, -0.0233,  0.0079,  0.0648,  0.0540,\n",
      "         0.0709,  0.0621,  0.0129, -0.0701,  0.0108,  0.0731, -0.0100,  0.0446,\n",
      "        -0.0181, -0.0555, -0.0652,  0.0438, -0.0628, -0.0811,  0.0021, -0.0611,\n",
      "        -0.0746,  0.0447, -0.0587, -0.0036,  0.0541,  0.0742,  0.0734,  0.0328,\n",
      "        -0.0321,  0.0366,  0.0319, -0.0816, -0.0667, -0.0555, -0.0042,  0.0107,\n",
      "        -0.0726, -0.0246, -0.0160,  0.0660,  0.0510,  0.0803,  0.0362, -0.0045,\n",
      "        -0.0705,  0.0591,  0.0207,  0.0616,  0.0517, -0.0787, -0.0007,  0.0347,\n",
      "        -0.0181,  0.0245,  0.0405,  0.0607,  0.0520, -0.0273, -0.0172, -0.0714,\n",
      "        -0.0248,  0.0163,  0.0454,  0.0308,  0.0010,  0.0378,  0.0815, -0.0750])), ('linear2.weight', tensor([[-0.0042, -0.0664, -0.0118,  ...,  0.0148, -0.0284,  0.0039],\n",
      "        [-0.0452,  0.0207,  0.0591,  ..., -0.0684, -0.0238,  0.0260],\n",
      "        [-0.0437,  0.0180,  0.0477,  ...,  0.0199, -0.0060, -0.0195],\n",
      "        ...,\n",
      "        [-0.0451,  0.0539,  0.0370,  ...,  0.0321,  0.0120,  0.0387],\n",
      "        [ 0.0475, -0.0599,  0.0200,  ..., -0.0546, -0.0012,  0.0291],\n",
      "        [ 0.0478, -0.0036, -0.0543,  ...,  0.0015, -0.0565,  0.0521]])), ('linear2.bias', tensor([-0.0103,  0.0295, -0.0524,  0.0209, -0.0312,  0.0028,  0.0680, -0.0655,\n",
      "        -0.0520,  0.0149, -0.0618,  0.0181, -0.0420,  0.0538,  0.0425, -0.0481,\n",
      "        -0.0220,  0.0223,  0.0516, -0.0697, -0.0291, -0.0276, -0.0583,  0.0142,\n",
      "         0.0250,  0.0228, -0.0127,  0.0575,  0.0518, -0.0053,  0.0385,  0.0021,\n",
      "         0.0387, -0.0391, -0.0334,  0.0156, -0.0209,  0.0030,  0.0457,  0.0301,\n",
      "        -0.0045,  0.0592, -0.0544,  0.0390, -0.0016,  0.0403, -0.0634,  0.0468,\n",
      "         0.0444,  0.0669,  0.0402, -0.0063,  0.0045, -0.0096,  0.0641, -0.0079,\n",
      "         0.0208,  0.0011,  0.0692,  0.0317, -0.0565,  0.0250, -0.0683,  0.0495,\n",
      "        -0.0664, -0.0450, -0.0109,  0.0369,  0.0547,  0.0643,  0.0341,  0.0659,\n",
      "        -0.0308, -0.0601, -0.0285,  0.0253,  0.0024,  0.0445,  0.0065,  0.0104,\n",
      "         0.0254, -0.0333,  0.0102, -0.0249, -0.0065, -0.0134,  0.0039, -0.0404,\n",
      "         0.0048,  0.0044, -0.0227,  0.0635,  0.0332, -0.0635, -0.0600, -0.0027,\n",
      "         0.0532, -0.0278,  0.0502, -0.0239])), ('linear3.weight', tensor([[-8.1859e-02,  5.4963e-02, -5.6116e-02, -8.6450e-02, -7.9618e-02,\n",
      "         -8.4659e-02, -3.4566e-02,  8.4525e-02,  8.7622e-02,  6.5951e-02,\n",
      "          2.6708e-02,  3.5574e-02, -6.0221e-03,  8.0275e-02, -6.1368e-02,\n",
      "          4.9290e-03,  3.5392e-02, -2.2645e-02,  4.4268e-02, -8.0110e-02,\n",
      "          1.4589e-02,  3.0174e-02,  2.8925e-02, -8.2486e-02, -2.5872e-02,\n",
      "          7.1676e-02,  2.6952e-02, -1.0749e-02, -5.6320e-02, -8.6459e-02,\n",
      "         -8.6584e-02, -5.4351e-02,  2.8330e-02, -2.1272e-02, -3.4326e-02,\n",
      "         -5.0077e-02,  2.4330e-02, -8.5856e-02, -3.6957e-02,  7.9977e-02,\n",
      "          9.6991e-02,  8.2000e-02,  9.6424e-02, -2.0202e-02,  9.6164e-02,\n",
      "         -7.6048e-02, -9.7211e-02, -8.4153e-02,  9.0702e-02, -1.5679e-03,\n",
      "         -2.0085e-02,  5.8475e-02, -5.4412e-02,  3.9156e-02,  3.3173e-02,\n",
      "          7.8190e-02, -8.9351e-02,  2.7967e-02, -5.2699e-02, -4.5874e-02,\n",
      "          4.4745e-02, -3.4582e-02,  2.5797e-02,  3.3519e-02, -5.4114e-02,\n",
      "          2.6085e-02,  6.4530e-02,  6.0624e-02,  9.4019e-02,  8.4863e-02,\n",
      "         -8.8824e-03, -7.7267e-02,  3.8065e-02,  7.8011e-02, -3.8461e-02,\n",
      "         -6.5697e-02,  1.2262e-02,  4.9022e-02,  1.2675e-02,  8.6289e-02,\n",
      "          6.7781e-02,  4.9048e-02, -5.3796e-02,  4.6017e-02, -7.0453e-02,\n",
      "         -1.0496e-02,  5.5595e-02, -2.7439e-02, -5.2598e-02,  1.3613e-02,\n",
      "          3.0768e-02,  1.5250e-02, -2.3559e-02,  2.3216e-02,  8.2579e-02,\n",
      "         -1.8082e-02,  3.2377e-02, -7.7281e-02,  5.8582e-02, -5.6018e-03],\n",
      "        [-2.1737e-03,  4.9144e-02,  8.5194e-02,  8.3546e-03,  5.2413e-02,\n",
      "          6.1892e-02, -6.5699e-02,  9.7719e-02, -9.6838e-02,  8.5933e-02,\n",
      "          6.6142e-02, -7.8098e-03,  8.5373e-02, -8.0669e-02,  4.8838e-02,\n",
      "          1.6007e-02,  2.3221e-02, -2.4227e-02,  9.2616e-02, -4.7297e-02,\n",
      "         -4.7309e-02, -3.6943e-04,  6.3139e-02, -8.0873e-02,  7.2832e-02,\n",
      "         -5.8740e-02,  9.6004e-02,  6.8465e-02,  1.9791e-02,  5.1360e-02,\n",
      "          7.3122e-02, -5.8274e-02,  9.7646e-02, -5.5470e-02,  1.6590e-02,\n",
      "         -5.6363e-02,  1.6818e-02, -3.7351e-02, -6.9838e-02, -4.6850e-02,\n",
      "         -1.2686e-02,  2.1933e-02, -2.1890e-02, -7.2976e-02,  8.5696e-02,\n",
      "          6.6278e-02, -3.1678e-02,  5.3716e-02, -4.1456e-02,  7.0112e-02,\n",
      "          1.7500e-03, -8.2864e-02,  1.1726e-02, -4.4551e-02,  6.1122e-02,\n",
      "         -8.6927e-02, -4.3267e-02,  1.9693e-02,  8.1164e-02,  2.6885e-02,\n",
      "          2.2644e-03,  5.2035e-02, -6.9280e-02,  9.4441e-02,  2.4128e-02,\n",
      "         -4.0068e-02,  7.8931e-02, -4.0139e-02, -4.9139e-02,  1.6601e-02,\n",
      "         -4.7312e-02,  6.6093e-02, -5.8181e-02, -8.6935e-02, -8.1730e-02,\n",
      "          2.3250e-03, -2.0783e-02, -4.8774e-02, -3.2974e-02,  9.1256e-02,\n",
      "          6.4540e-02,  6.0788e-02, -8.4923e-03,  7.0240e-02, -9.1425e-02,\n",
      "          1.4017e-02, -6.2668e-02,  3.6186e-03, -3.2159e-03, -9.8639e-02,\n",
      "         -2.4306e-02, -1.2926e-02, -1.1208e-02, -1.1007e-02,  7.8119e-02,\n",
      "          6.9694e-02,  7.6771e-02, -6.4797e-02, -8.8241e-02, -2.6725e-02],\n",
      "        [-4.6950e-02, -5.7878e-02, -4.2660e-02,  9.6962e-03,  5.0218e-02,\n",
      "          9.1794e-02, -9.1601e-02, -4.0121e-02,  2.6923e-02,  7.5591e-02,\n",
      "         -1.7488e-02, -4.9651e-02, -2.0451e-02, -1.3599e-02,  4.1437e-02,\n",
      "          7.1272e-02,  9.8382e-02,  4.9390e-02, -3.9955e-02, -1.1288e-02,\n",
      "          4.6374e-02, -7.7535e-02, -5.8219e-02,  6.1845e-02,  5.8048e-02,\n",
      "          1.8745e-02,  3.5735e-02, -6.5009e-02, -9.0972e-03,  8.0850e-02,\n",
      "          3.5748e-02, -5.1905e-02, -7.6213e-02, -2.7620e-02,  9.1213e-03,\n",
      "         -6.5099e-02,  6.7302e-02, -8.6544e-02,  5.0261e-02, -8.6582e-02,\n",
      "          7.2538e-02, -7.3985e-02, -3.2245e-03, -3.5631e-02, -8.1305e-02,\n",
      "         -1.2679e-02,  7.3839e-02, -5.7263e-02, -2.8822e-02,  9.6337e-04,\n",
      "          6.7876e-02, -8.5426e-02,  1.2920e-02, -1.2081e-02,  9.6181e-02,\n",
      "         -3.1630e-03, -9.9101e-02, -3.9246e-02, -6.3765e-02,  2.1755e-02,\n",
      "         -4.0034e-02,  7.2982e-02,  2.8868e-02, -4.9884e-02, -8.3014e-02,\n",
      "         -4.7947e-03,  9.7719e-02,  7.8436e-02, -9.8796e-03, -6.0552e-02,\n",
      "         -9.4831e-02, -1.2137e-02,  1.7098e-02,  4.1281e-02, -3.8697e-02,\n",
      "          8.1316e-02, -4.3466e-02,  3.1320e-02,  7.8142e-02,  2.1996e-02,\n",
      "          6.1583e-02,  3.6209e-02, -8.1611e-02, -4.0207e-02,  9.7864e-02,\n",
      "         -9.4649e-02, -7.6439e-02,  5.8250e-02, -6.1609e-02,  1.7509e-02,\n",
      "          8.5045e-02,  7.2830e-02, -3.8142e-02, -5.2286e-03,  3.7451e-02,\n",
      "          4.6779e-02,  2.6209e-02, -2.3014e-02, -7.2745e-02,  8.5597e-02],\n",
      "        [ 4.1696e-02,  4.4693e-02,  6.1973e-02, -9.9138e-03,  5.5230e-02,\n",
      "         -8.6240e-02,  1.6320e-02,  1.9276e-02,  4.6386e-02, -6.1514e-02,\n",
      "          6.4261e-02,  9.1878e-02, -6.6806e-02, -6.8039e-02, -1.1481e-02,\n",
      "          9.5905e-02, -9.8847e-02,  6.1363e-02, -6.6134e-02, -4.1346e-02,\n",
      "         -7.0979e-02, -4.8980e-02, -1.0452e-02,  9.5735e-03, -3.2604e-02,\n",
      "          2.2604e-02, -1.9193e-05,  4.8956e-02, -3.7671e-03,  7.6825e-02,\n",
      "          1.1480e-04,  9.3519e-02,  2.7575e-02,  3.2067e-02, -6.7589e-02,\n",
      "         -6.0556e-02,  2.5333e-02, -5.8154e-02,  1.8586e-02,  8.8252e-02,\n",
      "         -3.5308e-02, -6.5909e-02, -9.9277e-02, -2.2356e-02,  3.8486e-02,\n",
      "         -9.9173e-02,  7.8653e-02,  9.4884e-02, -1.6012e-02,  6.0038e-02,\n",
      "          6.4644e-02,  2.1986e-02,  6.3920e-02, -2.3612e-02, -5.1584e-02,\n",
      "          3.3839e-02,  6.3053e-02,  8.8806e-02,  6.1454e-02, -2.2593e-02,\n",
      "         -4.2546e-02,  7.3978e-02, -5.7074e-03,  7.6196e-02,  6.9998e-02,\n",
      "         -4.5981e-02,  1.3264e-02, -9.0404e-02, -4.2183e-02,  4.2104e-02,\n",
      "         -4.7168e-02, -1.4863e-03,  8.4832e-05,  3.0544e-02, -5.1999e-02,\n",
      "          9.6292e-02, -7.3996e-02, -5.1649e-02, -1.0851e-02,  6.0104e-02,\n",
      "          6.4677e-02,  9.2728e-02, -8.7749e-02, -9.2763e-02,  6.8107e-02,\n",
      "         -9.2449e-02, -9.1984e-02, -6.3421e-02, -4.8753e-02, -5.0742e-02,\n",
      "          8.6135e-03,  1.1766e-02, -9.2633e-02,  2.7062e-02, -1.8486e-02,\n",
      "          5.4209e-02,  7.6607e-02, -1.5315e-02,  1.8004e-02, -4.0003e-02],\n",
      "        [ 6.6454e-02,  5.5929e-02,  7.2999e-02,  3.9813e-02, -8.3831e-02,\n",
      "          7.3774e-03, -3.6408e-02, -8.4750e-02,  7.8808e-02, -8.4615e-02,\n",
      "          2.5438e-02,  5.3372e-02,  8.0464e-02, -6.1655e-02, -1.7745e-02,\n",
      "          9.7800e-02, -4.8533e-02, -1.6866e-02,  6.0858e-02,  7.9891e-02,\n",
      "         -4.2657e-02,  7.1293e-02,  6.4880e-02,  6.7515e-02, -9.9129e-02,\n",
      "         -4.6123e-02,  3.8089e-02,  7.0895e-02, -8.7748e-03,  5.8277e-02,\n",
      "         -4.9671e-02, -1.3719e-03, -3.0569e-02, -1.1523e-02,  2.0952e-02,\n",
      "          2.2758e-02,  9.2663e-02,  7.5245e-02,  6.0371e-02, -4.2461e-02,\n",
      "         -9.7548e-02, -7.2743e-02,  9.0799e-02, -6.7926e-02,  3.4070e-02,\n",
      "         -5.9770e-02, -9.1988e-02, -9.6402e-02,  5.9512e-02,  6.0051e-02,\n",
      "          4.5341e-02,  3.7750e-02, -6.3905e-02,  7.6300e-02,  4.4272e-02,\n",
      "         -3.7506e-02,  9.2099e-02, -8.7454e-02,  9.0623e-02,  5.1123e-02,\n",
      "         -8.7771e-02, -2.7548e-02, -4.0736e-02, -7.2736e-02,  3.7171e-02,\n",
      "          9.8917e-03,  5.2082e-02, -7.6377e-02, -6.6851e-02, -3.1641e-02,\n",
      "         -7.1990e-03, -4.6810e-02,  3.4162e-02, -6.0850e-02, -7.7988e-02,\n",
      "          4.7929e-02, -4.9367e-02,  5.4005e-02,  3.2642e-02, -7.2771e-02,\n",
      "         -7.8209e-02,  1.5981e-03, -8.9771e-02, -3.6514e-02, -8.2809e-02,\n",
      "         -2.8809e-02, -4.0658e-02, -7.9969e-02,  1.3079e-02,  9.4315e-02,\n",
      "          8.1098e-02,  1.4628e-02,  7.6222e-02,  7.5831e-02,  8.9282e-02,\n",
      "          8.9975e-02,  8.8806e-03, -6.6194e-02, -9.2579e-02, -8.0210e-02],\n",
      "        [ 9.0424e-02, -7.0654e-02,  1.5695e-02, -3.0525e-03,  3.2655e-02,\n",
      "          8.1709e-02,  4.8581e-02, -8.5740e-02,  7.0387e-02,  2.0039e-02,\n",
      "         -9.3993e-03,  6.1952e-02, -7.5213e-02, -2.0438e-02,  7.7954e-02,\n",
      "         -5.6431e-02,  1.7378e-02, -6.5140e-02,  9.0492e-02,  7.4408e-02,\n",
      "         -8.2079e-02,  3.7301e-02,  4.1933e-02,  2.0768e-03, -9.9183e-02,\n",
      "          3.5526e-02,  1.7915e-02, -1.4981e-03, -5.6192e-02, -6.3391e-02,\n",
      "          5.4214e-02,  1.9851e-02,  7.0704e-02,  5.5143e-02, -9.4359e-02,\n",
      "         -2.0447e-02, -5.4021e-02, -1.7544e-02,  3.1014e-02,  2.0043e-02,\n",
      "         -5.3172e-02,  9.0788e-02, -9.1185e-02, -3.2232e-02, -4.7469e-03,\n",
      "         -2.8208e-02, -7.6272e-02,  1.3877e-02,  4.2906e-02,  2.5806e-02,\n",
      "         -8.5831e-02, -3.2161e-03,  4.8048e-02,  2.3483e-02, -5.5108e-02,\n",
      "          9.5038e-02, -6.8033e-02,  2.8781e-02,  5.3509e-02,  1.1501e-02,\n",
      "         -3.9263e-02,  8.7513e-02, -5.2261e-02, -1.3199e-02, -8.9100e-02,\n",
      "          5.7819e-02, -1.0709e-02, -9.5532e-02,  2.2298e-02, -3.5143e-02,\n",
      "         -6.1559e-02,  4.6720e-02, -6.7011e-02,  9.2027e-02, -4.3895e-02,\n",
      "          9.0376e-03, -5.7872e-02, -6.8063e-02,  8.3585e-02,  9.3695e-02,\n",
      "         -2.8009e-02,  1.8826e-02, -7.6306e-02, -3.8887e-02,  6.5648e-02,\n",
      "         -6.9703e-02, -9.7531e-02,  2.4369e-02,  8.2048e-02,  3.1030e-02,\n",
      "          6.5589e-02, -2.2381e-02, -5.5507e-02,  3.6555e-02, -6.5690e-02,\n",
      "          2.9737e-02,  8.5040e-02, -8.1627e-02,  5.9282e-02,  7.2390e-02],\n",
      "        [ 4.0002e-02, -1.9877e-02,  4.3460e-02, -5.5065e-02,  4.3808e-02,\n",
      "          4.7897e-02, -4.5228e-02, -5.4103e-02,  1.9917e-02,  6.3860e-02,\n",
      "          3.3037e-02, -7.0828e-02, -9.6749e-02,  7.1200e-02,  6.5551e-02,\n",
      "         -4.7477e-02,  6.3970e-02, -9.6249e-02, -9.9156e-02, -5.8389e-02,\n",
      "          8.3984e-02, -8.8578e-02,  8.0181e-02,  6.5689e-02,  7.8271e-03,\n",
      "         -9.1994e-02,  6.6988e-03, -9.1188e-02, -1.4394e-02, -7.1553e-02,\n",
      "         -4.5837e-02,  6.1813e-03,  7.9895e-02, -1.9126e-02,  8.1019e-04,\n",
      "         -8.0004e-03, -9.5591e-02, -6.7938e-02,  6.3850e-02, -5.3796e-02,\n",
      "          9.8376e-02,  8.6002e-03,  4.2810e-02, -7.9046e-02,  7.5679e-02,\n",
      "          5.7380e-02,  2.6522e-02, -5.6602e-02, -2.3860e-02, -3.2694e-02,\n",
      "          3.3661e-03,  3.3369e-02, -2.6131e-02,  4.1486e-02, -2.4446e-02,\n",
      "          9.6503e-02, -5.4718e-02,  8.7951e-02,  4.1143e-02, -3.2901e-02,\n",
      "          9.9015e-02, -3.5997e-03, -3.4025e-03, -1.7800e-02,  6.0875e-02,\n",
      "         -2.8876e-02,  3.9300e-02, -7.8853e-02,  8.6979e-02,  7.3574e-02,\n",
      "         -4.1438e-02,  7.5618e-02, -7.5304e-02, -3.4147e-03,  7.0915e-02,\n",
      "         -4.9581e-03,  5.6163e-02, -3.9791e-02, -9.9715e-02, -4.1026e-03,\n",
      "          7.4236e-02,  5.5314e-02, -6.9833e-02, -9.5531e-02,  4.4018e-02,\n",
      "          4.5934e-02,  1.8303e-02, -7.7866e-02,  7.2832e-02,  3.8321e-03,\n",
      "         -3.2310e-02, -3.0326e-02, -7.6570e-02, -3.2393e-02, -7.6507e-02,\n",
      "          2.7752e-03,  9.2013e-02, -3.8422e-02,  1.5726e-02, -3.6031e-02],\n",
      "        [-4.2809e-02,  9.3418e-02,  8.5998e-02, -8.2695e-02,  8.4872e-02,\n",
      "         -4.7598e-02, -1.5656e-02, -3.0391e-03, -7.8345e-02, -1.0491e-02,\n",
      "         -8.6830e-02, -4.4549e-02, -5.4298e-02,  3.4726e-02, -7.2646e-02,\n",
      "         -1.1978e-02,  6.2996e-02, -5.3038e-02, -3.2611e-02, -1.3622e-02,\n",
      "         -8.0636e-02, -4.0322e-02, -2.5070e-02, -5.0331e-02,  6.6102e-02,\n",
      "          3.8139e-02, -3.5299e-02,  1.0892e-02,  5.3209e-02, -5.3694e-02,\n",
      "          3.3962e-02,  5.4020e-02, -5.4706e-02,  2.5151e-02, -4.4926e-02,\n",
      "         -8.8154e-02,  2.8000e-02,  4.3376e-02,  2.4858e-02, -3.0191e-02,\n",
      "         -5.4838e-02,  2.1992e-02, -2.3021e-02, -1.9184e-02, -5.6297e-02,\n",
      "         -4.2148e-02,  4.6704e-02, -1.3622e-02,  5.3570e-02,  9.5940e-02,\n",
      "         -8.6381e-02,  3.4196e-02, -2.1907e-02,  9.6421e-02,  5.8558e-02,\n",
      "          5.4537e-02, -5.8824e-02, -7.9939e-02,  2.6643e-03, -4.0186e-02,\n",
      "         -8.2115e-02, -3.2209e-02, -8.1563e-02,  8.3376e-02, -5.2503e-02,\n",
      "          6.9394e-02, -5.9260e-02, -6.3681e-02, -4.5775e-02,  9.5779e-02,\n",
      "         -8.9759e-02,  8.4587e-03,  6.0631e-02, -5.7599e-02,  6.8412e-03,\n",
      "         -6.3244e-02, -6.3762e-02, -4.6935e-02, -2.6984e-02,  4.3818e-02,\n",
      "          8.8496e-02,  2.4446e-02, -1.0030e-02,  3.2385e-02, -1.9681e-02,\n",
      "          4.8239e-02,  8.7874e-02, -2.6989e-02, -3.2352e-03,  7.1018e-02,\n",
      "         -9.4258e-03, -9.4267e-02,  4.9120e-02,  3.2491e-02,  5.4577e-02,\n",
      "          6.0579e-02,  2.4154e-04,  3.7269e-02,  3.7370e-02, -1.6724e-02],\n",
      "        [-4.4582e-02, -9.4577e-02, -6.8956e-02, -8.7897e-02,  4.4615e-02,\n",
      "          2.3344e-02, -6.9625e-02,  8.7126e-02,  3.0823e-02,  7.3412e-02,\n",
      "         -6.5325e-02,  6.6556e-03,  5.4836e-02,  3.3985e-02,  4.6642e-02,\n",
      "         -2.7303e-02, -6.9832e-02, -1.3864e-02,  9.9051e-02, -2.5077e-02,\n",
      "         -4.4494e-02, -3.7682e-02, -8.1260e-02,  1.5018e-02,  3.5875e-02,\n",
      "          3.4807e-02, -2.1883e-02,  7.0419e-02, -5.0020e-02, -1.8996e-02,\n",
      "          6.7029e-02, -5.3086e-03,  3.0149e-03,  5.2770e-02, -6.4053e-03,\n",
      "          2.3478e-02, -5.5279e-02, -4.9624e-03, -8.8719e-03, -4.1304e-02,\n",
      "          7.1579e-02, -3.7593e-02, -6.0884e-02,  6.7667e-02,  6.3293e-02,\n",
      "         -5.7820e-02,  5.4275e-02, -1.8266e-02, -3.4324e-02, -2.3063e-02,\n",
      "          6.8039e-02, -4.3113e-02,  1.3769e-02,  4.6547e-02,  2.7215e-02,\n",
      "         -7.8149e-02,  3.4554e-02, -7.0489e-02,  9.1348e-03, -7.7060e-02,\n",
      "          7.1846e-02,  3.0306e-02, -6.1545e-02, -2.7564e-02,  7.3886e-02,\n",
      "         -5.9818e-02,  5.9650e-02,  6.5562e-02,  4.0175e-02, -9.5528e-02,\n",
      "         -8.4671e-02,  8.9506e-02, -1.0494e-02, -4.6461e-03, -2.3212e-02,\n",
      "         -6.0118e-02, -1.1317e-02, -4.2227e-02, -3.3702e-02, -4.1652e-02,\n",
      "          7.4687e-02, -2.9645e-02, -3.5168e-02,  8.1746e-02,  6.3201e-02,\n",
      "          8.2489e-02,  6.6744e-02, -9.2885e-03,  3.8179e-02, -9.6297e-02,\n",
      "         -3.6300e-02, -7.0654e-02,  1.9282e-02,  5.0511e-02, -2.3786e-02,\n",
      "         -7.6305e-03, -7.5311e-02, -8.4680e-02,  8.5115e-02,  1.1903e-02],\n",
      "        [ 8.8173e-02,  2.7937e-02, -4.9321e-02, -3.5425e-02,  9.6030e-02,\n",
      "          8.4402e-02, -1.4313e-02, -6.5185e-02, -6.0675e-02, -6.3354e-03,\n",
      "         -1.5803e-02, -6.1468e-02,  1.9881e-02,  4.5379e-02, -8.8415e-02,\n",
      "         -6.1101e-02,  6.9037e-02,  9.3889e-02, -1.1827e-02, -9.0557e-02,\n",
      "         -9.4272e-02,  3.6580e-02,  6.0235e-02, -7.3008e-02,  4.2090e-02,\n",
      "         -4.0497e-03, -4.9899e-02, -8.1717e-02, -6.8638e-02, -8.9444e-02,\n",
      "          4.5182e-02, -7.6639e-02, -4.0385e-02, -3.3123e-02, -1.1410e-02,\n",
      "          9.0826e-02, -7.7282e-02,  7.0562e-02,  9.0649e-02,  5.3056e-02,\n",
      "         -7.4187e-02, -5.4747e-02,  3.1456e-03,  1.6454e-02, -9.0918e-02,\n",
      "          3.7263e-02, -2.1833e-02,  5.8672e-02,  4.7486e-02,  5.0141e-02,\n",
      "          6.2007e-02, -5.6279e-02,  8.5555e-02,  6.8694e-02, -7.9228e-02,\n",
      "         -5.7107e-02, -7.2981e-02, -5.0564e-02, -4.9943e-02, -1.0018e-02,\n",
      "          2.9700e-02,  2.9274e-02, -1.1256e-02,  7.8468e-02,  1.9917e-02,\n",
      "          8.3517e-02, -3.7203e-02,  3.4996e-02,  3.0142e-02,  7.2039e-02,\n",
      "         -8.5470e-02,  3.4698e-02, -2.4628e-02, -5.7621e-02,  8.0619e-02,\n",
      "          4.1994e-02,  1.8419e-02, -6.6855e-02, -7.1815e-03, -9.7656e-02,\n",
      "         -7.6045e-02, -8.9471e-02,  1.8276e-02,  4.6263e-02, -9.6497e-02,\n",
      "         -7.3275e-02,  8.0950e-02, -6.5101e-02,  1.9448e-02, -7.5553e-03,\n",
      "         -4.3875e-02,  3.7131e-03,  9.2268e-02, -2.8359e-02,  7.3117e-02,\n",
      "          2.8109e-02,  7.8418e-02,  2.2319e-02,  8.0144e-02, -6.3643e-02]])), ('linear3.bias', tensor([ 0.0643, -0.0388,  0.0781,  0.0300,  0.0928, -0.0030, -0.0584, -0.0098,\n",
      "         0.0117, -0.0322]))])\n",
      "Net_A1_HT: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 0., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [0., 1., 0.]]]])), ('conv1.bias', tensor([0., 0., 0., 0.])), ('conv2.weight', tensor([[[[ 0.0277,  0.1149, -0.1208],\n",
      "          [ 0.1161,  0.1605, -0.0957],\n",
      "          [-0.1079, -0.1183, -0.0668]],\n",
      "\n",
      "         [[-0.1547, -0.0691, -0.1027],\n",
      "          [-0.0794, -0.0236,  0.0004],\n",
      "          [-0.0838,  0.0406, -0.0066]],\n",
      "\n",
      "         [[ 0.0825, -0.1004,  0.0103],\n",
      "          [ 0.0283,  0.0741, -0.0702],\n",
      "          [-0.0884,  0.0566, -0.1151]],\n",
      "\n",
      "         [[ 0.0678,  0.1228, -0.0446],\n",
      "          [ 0.1102,  0.0567, -0.1177],\n",
      "          [-0.0948,  0.1466,  0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0481, -0.1236, -0.0548],\n",
      "          [-0.1211,  0.0455, -0.0900],\n",
      "          [-0.0881, -0.0630,  0.0127]],\n",
      "\n",
      "         [[-0.0302, -0.0815, -0.0060],\n",
      "          [-0.1386, -0.0463,  0.0019],\n",
      "          [-0.0203, -0.0756,  0.0394]],\n",
      "\n",
      "         [[ 0.0220,  0.0737,  0.0375],\n",
      "          [ 0.1448, -0.0480,  0.0053],\n",
      "          [-0.0264, -0.1254,  0.0408]],\n",
      "\n",
      "         [[-0.1433, -0.0717, -0.1519],\n",
      "          [-0.0284,  0.0483,  0.1254],\n",
      "          [ 0.1048, -0.1471, -0.0192]]],\n",
      "\n",
      "\n",
      "        [[[-0.1214, -0.0114, -0.0650],\n",
      "          [ 0.0441,  0.1437, -0.0815],\n",
      "          [-0.1046,  0.1386, -0.0093]],\n",
      "\n",
      "         [[-0.1239,  0.0977,  0.1428],\n",
      "          [-0.0667,  0.0277, -0.1622],\n",
      "          [-0.0084, -0.1623, -0.0426]],\n",
      "\n",
      "         [[-0.0744, -0.0416, -0.0755],\n",
      "          [ 0.1014, -0.0479,  0.1453],\n",
      "          [ 0.1127,  0.0843,  0.1025]],\n",
      "\n",
      "         [[-0.1527,  0.0352,  0.0479],\n",
      "          [-0.0681, -0.1173, -0.1619],\n",
      "          [ 0.1134, -0.1410,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1035,  0.1176, -0.1514],\n",
      "          [-0.0786, -0.0893, -0.0645],\n",
      "          [ 0.0692,  0.0216,  0.0929]],\n",
      "\n",
      "         [[ 0.0940,  0.0771, -0.0682],\n",
      "          [-0.0937,  0.1657,  0.0603],\n",
      "          [-0.0226, -0.0135, -0.0929]],\n",
      "\n",
      "         [[ 0.0138, -0.1619,  0.0119],\n",
      "          [ 0.0873,  0.0704, -0.1510],\n",
      "          [ 0.1643, -0.0898, -0.1235]],\n",
      "\n",
      "         [[-0.0768,  0.1207, -0.0881],\n",
      "          [-0.0107, -0.1406,  0.0444],\n",
      "          [-0.0925, -0.1311,  0.0439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1248,  0.0391,  0.1382],\n",
      "          [-0.1300, -0.0065, -0.1247],\n",
      "          [ 0.0092,  0.0483,  0.0728]],\n",
      "\n",
      "         [[-0.0111, -0.1385, -0.0405],\n",
      "          [ 0.0897, -0.1337,  0.0845],\n",
      "          [ 0.0412,  0.1241,  0.1158]],\n",
      "\n",
      "         [[-0.0636, -0.1513, -0.1154],\n",
      "          [ 0.0560, -0.0266,  0.1168],\n",
      "          [-0.0036, -0.1158, -0.0499]],\n",
      "\n",
      "         [[-0.0608,  0.0503, -0.0282],\n",
      "          [ 0.1367, -0.0551, -0.0871],\n",
      "          [-0.0443,  0.1156, -0.0237]]],\n",
      "\n",
      "\n",
      "        [[[-0.0578,  0.1307,  0.1498],\n",
      "          [ 0.1168,  0.1255, -0.0361],\n",
      "          [ 0.0610,  0.0237,  0.0126]],\n",
      "\n",
      "         [[-0.1344,  0.0685, -0.1344],\n",
      "          [ 0.1060,  0.1278,  0.1221],\n",
      "          [-0.0153, -0.1446, -0.1478]],\n",
      "\n",
      "         [[ 0.1608,  0.0608, -0.1501],\n",
      "          [ 0.0874, -0.0374, -0.1175],\n",
      "          [ 0.1032,  0.1281,  0.0354]],\n",
      "\n",
      "         [[-0.0255, -0.0660, -0.1522],\n",
      "          [ 0.1521, -0.0384,  0.1535],\n",
      "          [ 0.0805,  0.1001,  0.0620]]]])), ('conv2.bias', tensor([ 0.1004,  0.0124, -0.1523, -0.0778, -0.1434,  0.1143])), ('linear1.weight', tensor([[-0.0275,  0.0443,  0.0005,  ..., -0.0383,  0.0138, -0.0651],\n",
      "        [ 0.0233, -0.0665, -0.0592,  ...,  0.0673, -0.0275, -0.0332],\n",
      "        [ 0.0632,  0.0485, -0.0634,  ..., -0.0548,  0.0289, -0.0629],\n",
      "        ...,\n",
      "        [ 0.0778,  0.0472, -0.0498,  ..., -0.0364,  0.0123,  0.0035],\n",
      "        [-0.0745,  0.0345, -0.0013,  ...,  0.0689, -0.0481, -0.0798],\n",
      "        [ 0.0390, -0.0745, -0.0550,  ...,  0.0629,  0.0341, -0.0304]])), ('linear1.bias', tensor([-0.0615, -0.0117,  0.0083, -0.0375, -0.0580,  0.0219, -0.0233, -0.0567,\n",
      "        -0.0102, -0.0006,  0.0032,  0.0647, -0.0771,  0.0072,  0.0516,  0.0269,\n",
      "        -0.0402, -0.0172, -0.0466, -0.0546, -0.0268, -0.0388, -0.0094,  0.0358,\n",
      "        -0.0276,  0.0461,  0.0257,  0.0505,  0.0458,  0.0628,  0.0648, -0.0669,\n",
      "        -0.0587,  0.0765, -0.0807, -0.0726, -0.0490, -0.0641,  0.0527, -0.0764,\n",
      "         0.0208,  0.0653, -0.0799,  0.0142,  0.0747,  0.0797, -0.0318, -0.0208,\n",
      "        -0.0451,  0.0541,  0.0603,  0.0626,  0.0525, -0.0668, -0.0755, -0.0148,\n",
      "        -0.0544, -0.0346, -0.0522, -0.0331, -0.0085, -0.0209,  0.0567,  0.0244,\n",
      "        -0.0542, -0.0250, -0.0556,  0.0445,  0.0544, -0.0008,  0.0119,  0.0752,\n",
      "         0.0406,  0.0255, -0.0497,  0.0692,  0.0801, -0.0405, -0.0339,  0.0262,\n",
      "        -0.0640, -0.0108,  0.0157,  0.0221,  0.0672,  0.0356, -0.0687, -0.0281,\n",
      "         0.0106, -0.0533,  0.0336,  0.0470, -0.0289, -0.0344,  0.0392,  0.0199,\n",
      "        -0.0141, -0.0644,  0.0807, -0.0422,  0.0643,  0.0413, -0.0112,  0.0028,\n",
      "         0.0056,  0.0735, -0.0429,  0.0387, -0.0054, -0.0104,  0.0050,  0.0644,\n",
      "        -0.0451, -0.0361, -0.0785,  0.0084,  0.0092, -0.0086, -0.0058, -0.0072,\n",
      "         0.0490,  0.0569, -0.0599, -0.0766, -0.0016,  0.0697, -0.0089,  0.0085,\n",
      "        -0.0793,  0.0716, -0.0429, -0.0049, -0.0233,  0.0079,  0.0648,  0.0540,\n",
      "         0.0709,  0.0621,  0.0129, -0.0701,  0.0108,  0.0731, -0.0100,  0.0446,\n",
      "        -0.0181, -0.0555, -0.0652,  0.0438, -0.0628, -0.0811,  0.0021, -0.0611,\n",
      "        -0.0746,  0.0447, -0.0587, -0.0036,  0.0541,  0.0742,  0.0734,  0.0328,\n",
      "        -0.0321,  0.0366,  0.0319, -0.0816, -0.0667, -0.0555, -0.0042,  0.0107,\n",
      "        -0.0726, -0.0246, -0.0160,  0.0660,  0.0510,  0.0803,  0.0362, -0.0045,\n",
      "        -0.0705,  0.0591,  0.0207,  0.0616,  0.0517, -0.0787, -0.0007,  0.0347,\n",
      "        -0.0181,  0.0245,  0.0405,  0.0607,  0.0520, -0.0273, -0.0172, -0.0714,\n",
      "        -0.0248,  0.0163,  0.0454,  0.0308,  0.0010,  0.0378,  0.0815, -0.0750])), ('linear2.weight', tensor([[-0.0042, -0.0664, -0.0118,  ...,  0.0148, -0.0284,  0.0039],\n",
      "        [-0.0452,  0.0207,  0.0591,  ..., -0.0684, -0.0238,  0.0260],\n",
      "        [-0.0437,  0.0180,  0.0477,  ...,  0.0199, -0.0060, -0.0195],\n",
      "        ...,\n",
      "        [-0.0451,  0.0539,  0.0370,  ...,  0.0321,  0.0120,  0.0387],\n",
      "        [ 0.0475, -0.0599,  0.0200,  ..., -0.0546, -0.0012,  0.0291],\n",
      "        [ 0.0478, -0.0036, -0.0543,  ...,  0.0015, -0.0565,  0.0521]])), ('linear2.bias', tensor([-0.0103,  0.0295, -0.0524,  0.0209, -0.0312,  0.0028,  0.0680, -0.0655,\n",
      "        -0.0520,  0.0149, -0.0618,  0.0181, -0.0420,  0.0538,  0.0425, -0.0481,\n",
      "        -0.0220,  0.0223,  0.0516, -0.0697, -0.0291, -0.0276, -0.0583,  0.0142,\n",
      "         0.0250,  0.0228, -0.0127,  0.0575,  0.0518, -0.0053,  0.0385,  0.0021,\n",
      "         0.0387, -0.0391, -0.0334,  0.0156, -0.0209,  0.0030,  0.0457,  0.0301,\n",
      "        -0.0045,  0.0592, -0.0544,  0.0390, -0.0016,  0.0403, -0.0634,  0.0468,\n",
      "         0.0444,  0.0669,  0.0402, -0.0063,  0.0045, -0.0096,  0.0641, -0.0079,\n",
      "         0.0208,  0.0011,  0.0692,  0.0317, -0.0565,  0.0250, -0.0683,  0.0495,\n",
      "        -0.0664, -0.0450, -0.0109,  0.0369,  0.0547,  0.0643,  0.0341,  0.0659,\n",
      "        -0.0308, -0.0601, -0.0285,  0.0253,  0.0024,  0.0445,  0.0065,  0.0104,\n",
      "         0.0254, -0.0333,  0.0102, -0.0249, -0.0065, -0.0134,  0.0039, -0.0404,\n",
      "         0.0048,  0.0044, -0.0227,  0.0635,  0.0332, -0.0635, -0.0600, -0.0027,\n",
      "         0.0532, -0.0278,  0.0502, -0.0239])), ('linear3.weight', tensor([[-8.1859e-02,  5.4963e-02, -5.6116e-02, -8.6450e-02, -7.9618e-02,\n",
      "         -8.4659e-02, -3.4566e-02,  8.4525e-02,  8.7622e-02,  6.5951e-02,\n",
      "          2.6708e-02,  3.5574e-02, -6.0221e-03,  8.0275e-02, -6.1368e-02,\n",
      "          4.9290e-03,  3.5392e-02, -2.2645e-02,  4.4268e-02, -8.0110e-02,\n",
      "          1.4589e-02,  3.0174e-02,  2.8925e-02, -8.2486e-02, -2.5872e-02,\n",
      "          7.1676e-02,  2.6952e-02, -1.0749e-02, -5.6320e-02, -8.6459e-02,\n",
      "         -8.6584e-02, -5.4351e-02,  2.8330e-02, -2.1272e-02, -3.4326e-02,\n",
      "         -5.0077e-02,  2.4330e-02, -8.5856e-02, -3.6957e-02,  7.9977e-02,\n",
      "          9.6991e-02,  8.2000e-02,  9.6424e-02, -2.0202e-02,  9.6164e-02,\n",
      "         -7.6048e-02, -9.7211e-02, -8.4153e-02,  9.0702e-02, -1.5679e-03,\n",
      "         -2.0085e-02,  5.8475e-02, -5.4412e-02,  3.9156e-02,  3.3173e-02,\n",
      "          7.8190e-02, -8.9351e-02,  2.7967e-02, -5.2699e-02, -4.5874e-02,\n",
      "          4.4745e-02, -3.4582e-02,  2.5797e-02,  3.3519e-02, -5.4114e-02,\n",
      "          2.6085e-02,  6.4530e-02,  6.0624e-02,  9.4019e-02,  8.4863e-02,\n",
      "         -8.8824e-03, -7.7267e-02,  3.8065e-02,  7.8011e-02, -3.8461e-02,\n",
      "         -6.5697e-02,  1.2262e-02,  4.9022e-02,  1.2675e-02,  8.6289e-02,\n",
      "          6.7781e-02,  4.9048e-02, -5.3796e-02,  4.6017e-02, -7.0453e-02,\n",
      "         -1.0496e-02,  5.5595e-02, -2.7439e-02, -5.2598e-02,  1.3613e-02,\n",
      "          3.0768e-02,  1.5250e-02, -2.3559e-02,  2.3216e-02,  8.2579e-02,\n",
      "         -1.8082e-02,  3.2377e-02, -7.7281e-02,  5.8582e-02, -5.6018e-03],\n",
      "        [-2.1737e-03,  4.9144e-02,  8.5194e-02,  8.3546e-03,  5.2413e-02,\n",
      "          6.1892e-02, -6.5699e-02,  9.7719e-02, -9.6838e-02,  8.5933e-02,\n",
      "          6.6142e-02, -7.8098e-03,  8.5373e-02, -8.0669e-02,  4.8838e-02,\n",
      "          1.6007e-02,  2.3221e-02, -2.4227e-02,  9.2616e-02, -4.7297e-02,\n",
      "         -4.7309e-02, -3.6943e-04,  6.3139e-02, -8.0873e-02,  7.2832e-02,\n",
      "         -5.8740e-02,  9.6004e-02,  6.8465e-02,  1.9791e-02,  5.1360e-02,\n",
      "          7.3122e-02, -5.8274e-02,  9.7646e-02, -5.5470e-02,  1.6590e-02,\n",
      "         -5.6363e-02,  1.6818e-02, -3.7351e-02, -6.9838e-02, -4.6850e-02,\n",
      "         -1.2686e-02,  2.1933e-02, -2.1890e-02, -7.2976e-02,  8.5696e-02,\n",
      "          6.6278e-02, -3.1678e-02,  5.3716e-02, -4.1456e-02,  7.0112e-02,\n",
      "          1.7500e-03, -8.2864e-02,  1.1726e-02, -4.4551e-02,  6.1122e-02,\n",
      "         -8.6927e-02, -4.3267e-02,  1.9693e-02,  8.1164e-02,  2.6885e-02,\n",
      "          2.2644e-03,  5.2035e-02, -6.9280e-02,  9.4441e-02,  2.4128e-02,\n",
      "         -4.0068e-02,  7.8931e-02, -4.0139e-02, -4.9139e-02,  1.6601e-02,\n",
      "         -4.7312e-02,  6.6093e-02, -5.8181e-02, -8.6935e-02, -8.1730e-02,\n",
      "          2.3250e-03, -2.0783e-02, -4.8774e-02, -3.2974e-02,  9.1256e-02,\n",
      "          6.4540e-02,  6.0788e-02, -8.4923e-03,  7.0240e-02, -9.1425e-02,\n",
      "          1.4017e-02, -6.2668e-02,  3.6186e-03, -3.2159e-03, -9.8639e-02,\n",
      "         -2.4306e-02, -1.2926e-02, -1.1208e-02, -1.1007e-02,  7.8119e-02,\n",
      "          6.9694e-02,  7.6771e-02, -6.4797e-02, -8.8241e-02, -2.6725e-02],\n",
      "        [-4.6950e-02, -5.7878e-02, -4.2660e-02,  9.6962e-03,  5.0218e-02,\n",
      "          9.1794e-02, -9.1601e-02, -4.0121e-02,  2.6923e-02,  7.5591e-02,\n",
      "         -1.7488e-02, -4.9651e-02, -2.0451e-02, -1.3599e-02,  4.1437e-02,\n",
      "          7.1272e-02,  9.8382e-02,  4.9390e-02, -3.9955e-02, -1.1288e-02,\n",
      "          4.6374e-02, -7.7535e-02, -5.8219e-02,  6.1845e-02,  5.8048e-02,\n",
      "          1.8745e-02,  3.5735e-02, -6.5009e-02, -9.0972e-03,  8.0850e-02,\n",
      "          3.5748e-02, -5.1905e-02, -7.6213e-02, -2.7620e-02,  9.1213e-03,\n",
      "         -6.5099e-02,  6.7302e-02, -8.6544e-02,  5.0261e-02, -8.6582e-02,\n",
      "          7.2538e-02, -7.3985e-02, -3.2245e-03, -3.5631e-02, -8.1305e-02,\n",
      "         -1.2679e-02,  7.3839e-02, -5.7263e-02, -2.8822e-02,  9.6337e-04,\n",
      "          6.7876e-02, -8.5426e-02,  1.2920e-02, -1.2081e-02,  9.6181e-02,\n",
      "         -3.1630e-03, -9.9101e-02, -3.9246e-02, -6.3765e-02,  2.1755e-02,\n",
      "         -4.0034e-02,  7.2982e-02,  2.8868e-02, -4.9884e-02, -8.3014e-02,\n",
      "         -4.7947e-03,  9.7719e-02,  7.8436e-02, -9.8796e-03, -6.0552e-02,\n",
      "         -9.4831e-02, -1.2137e-02,  1.7098e-02,  4.1281e-02, -3.8697e-02,\n",
      "          8.1316e-02, -4.3466e-02,  3.1320e-02,  7.8142e-02,  2.1996e-02,\n",
      "          6.1583e-02,  3.6209e-02, -8.1611e-02, -4.0207e-02,  9.7864e-02,\n",
      "         -9.4649e-02, -7.6439e-02,  5.8250e-02, -6.1609e-02,  1.7509e-02,\n",
      "          8.5045e-02,  7.2830e-02, -3.8142e-02, -5.2286e-03,  3.7451e-02,\n",
      "          4.6779e-02,  2.6209e-02, -2.3014e-02, -7.2745e-02,  8.5597e-02],\n",
      "        [ 4.1696e-02,  4.4693e-02,  6.1973e-02, -9.9138e-03,  5.5230e-02,\n",
      "         -8.6240e-02,  1.6320e-02,  1.9276e-02,  4.6386e-02, -6.1514e-02,\n",
      "          6.4261e-02,  9.1878e-02, -6.6806e-02, -6.8039e-02, -1.1481e-02,\n",
      "          9.5905e-02, -9.8847e-02,  6.1363e-02, -6.6134e-02, -4.1346e-02,\n",
      "         -7.0979e-02, -4.8980e-02, -1.0452e-02,  9.5735e-03, -3.2604e-02,\n",
      "          2.2604e-02, -1.9193e-05,  4.8956e-02, -3.7671e-03,  7.6825e-02,\n",
      "          1.1480e-04,  9.3519e-02,  2.7575e-02,  3.2067e-02, -6.7589e-02,\n",
      "         -6.0556e-02,  2.5333e-02, -5.8154e-02,  1.8586e-02,  8.8252e-02,\n",
      "         -3.5308e-02, -6.5909e-02, -9.9277e-02, -2.2356e-02,  3.8486e-02,\n",
      "         -9.9173e-02,  7.8653e-02,  9.4884e-02, -1.6012e-02,  6.0038e-02,\n",
      "          6.4644e-02,  2.1986e-02,  6.3920e-02, -2.3612e-02, -5.1584e-02,\n",
      "          3.3839e-02,  6.3053e-02,  8.8806e-02,  6.1454e-02, -2.2593e-02,\n",
      "         -4.2546e-02,  7.3978e-02, -5.7074e-03,  7.6196e-02,  6.9998e-02,\n",
      "         -4.5981e-02,  1.3264e-02, -9.0404e-02, -4.2183e-02,  4.2104e-02,\n",
      "         -4.7168e-02, -1.4863e-03,  8.4832e-05,  3.0544e-02, -5.1999e-02,\n",
      "          9.6292e-02, -7.3996e-02, -5.1649e-02, -1.0851e-02,  6.0104e-02,\n",
      "          6.4677e-02,  9.2728e-02, -8.7749e-02, -9.2763e-02,  6.8107e-02,\n",
      "         -9.2449e-02, -9.1984e-02, -6.3421e-02, -4.8753e-02, -5.0742e-02,\n",
      "          8.6135e-03,  1.1766e-02, -9.2633e-02,  2.7062e-02, -1.8486e-02,\n",
      "          5.4209e-02,  7.6607e-02, -1.5315e-02,  1.8004e-02, -4.0003e-02],\n",
      "        [ 6.6454e-02,  5.5929e-02,  7.2999e-02,  3.9813e-02, -8.3831e-02,\n",
      "          7.3774e-03, -3.6408e-02, -8.4750e-02,  7.8808e-02, -8.4615e-02,\n",
      "          2.5438e-02,  5.3372e-02,  8.0464e-02, -6.1655e-02, -1.7745e-02,\n",
      "          9.7800e-02, -4.8533e-02, -1.6866e-02,  6.0858e-02,  7.9891e-02,\n",
      "         -4.2657e-02,  7.1293e-02,  6.4880e-02,  6.7515e-02, -9.9129e-02,\n",
      "         -4.6123e-02,  3.8089e-02,  7.0895e-02, -8.7748e-03,  5.8277e-02,\n",
      "         -4.9671e-02, -1.3719e-03, -3.0569e-02, -1.1523e-02,  2.0952e-02,\n",
      "          2.2758e-02,  9.2663e-02,  7.5245e-02,  6.0371e-02, -4.2461e-02,\n",
      "         -9.7548e-02, -7.2743e-02,  9.0799e-02, -6.7926e-02,  3.4070e-02,\n",
      "         -5.9770e-02, -9.1988e-02, -9.6402e-02,  5.9512e-02,  6.0051e-02,\n",
      "          4.5341e-02,  3.7750e-02, -6.3905e-02,  7.6300e-02,  4.4272e-02,\n",
      "         -3.7506e-02,  9.2099e-02, -8.7454e-02,  9.0623e-02,  5.1123e-02,\n",
      "         -8.7771e-02, -2.7548e-02, -4.0736e-02, -7.2736e-02,  3.7171e-02,\n",
      "          9.8917e-03,  5.2082e-02, -7.6377e-02, -6.6851e-02, -3.1641e-02,\n",
      "         -7.1990e-03, -4.6810e-02,  3.4162e-02, -6.0850e-02, -7.7988e-02,\n",
      "          4.7929e-02, -4.9367e-02,  5.4005e-02,  3.2642e-02, -7.2771e-02,\n",
      "         -7.8209e-02,  1.5981e-03, -8.9771e-02, -3.6514e-02, -8.2809e-02,\n",
      "         -2.8809e-02, -4.0658e-02, -7.9969e-02,  1.3079e-02,  9.4315e-02,\n",
      "          8.1098e-02,  1.4628e-02,  7.6222e-02,  7.5831e-02,  8.9282e-02,\n",
      "          8.9975e-02,  8.8806e-03, -6.6194e-02, -9.2579e-02, -8.0210e-02],\n",
      "        [ 9.0424e-02, -7.0654e-02,  1.5695e-02, -3.0525e-03,  3.2655e-02,\n",
      "          8.1709e-02,  4.8581e-02, -8.5740e-02,  7.0387e-02,  2.0039e-02,\n",
      "         -9.3993e-03,  6.1952e-02, -7.5213e-02, -2.0438e-02,  7.7954e-02,\n",
      "         -5.6431e-02,  1.7378e-02, -6.5140e-02,  9.0492e-02,  7.4408e-02,\n",
      "         -8.2079e-02,  3.7301e-02,  4.1933e-02,  2.0768e-03, -9.9183e-02,\n",
      "          3.5526e-02,  1.7915e-02, -1.4981e-03, -5.6192e-02, -6.3391e-02,\n",
      "          5.4214e-02,  1.9851e-02,  7.0704e-02,  5.5143e-02, -9.4359e-02,\n",
      "         -2.0447e-02, -5.4021e-02, -1.7544e-02,  3.1014e-02,  2.0043e-02,\n",
      "         -5.3172e-02,  9.0788e-02, -9.1185e-02, -3.2232e-02, -4.7469e-03,\n",
      "         -2.8208e-02, -7.6272e-02,  1.3877e-02,  4.2906e-02,  2.5806e-02,\n",
      "         -8.5831e-02, -3.2161e-03,  4.8048e-02,  2.3483e-02, -5.5108e-02,\n",
      "          9.5038e-02, -6.8033e-02,  2.8781e-02,  5.3509e-02,  1.1501e-02,\n",
      "         -3.9263e-02,  8.7513e-02, -5.2261e-02, -1.3199e-02, -8.9100e-02,\n",
      "          5.7819e-02, -1.0709e-02, -9.5532e-02,  2.2298e-02, -3.5143e-02,\n",
      "         -6.1559e-02,  4.6720e-02, -6.7011e-02,  9.2027e-02, -4.3895e-02,\n",
      "          9.0376e-03, -5.7872e-02, -6.8063e-02,  8.3585e-02,  9.3695e-02,\n",
      "         -2.8009e-02,  1.8826e-02, -7.6306e-02, -3.8887e-02,  6.5648e-02,\n",
      "         -6.9703e-02, -9.7531e-02,  2.4369e-02,  8.2048e-02,  3.1030e-02,\n",
      "          6.5589e-02, -2.2381e-02, -5.5507e-02,  3.6555e-02, -6.5690e-02,\n",
      "          2.9737e-02,  8.5040e-02, -8.1627e-02,  5.9282e-02,  7.2390e-02],\n",
      "        [ 4.0002e-02, -1.9877e-02,  4.3460e-02, -5.5065e-02,  4.3808e-02,\n",
      "          4.7897e-02, -4.5228e-02, -5.4103e-02,  1.9917e-02,  6.3860e-02,\n",
      "          3.3037e-02, -7.0828e-02, -9.6749e-02,  7.1200e-02,  6.5551e-02,\n",
      "         -4.7477e-02,  6.3970e-02, -9.6249e-02, -9.9156e-02, -5.8389e-02,\n",
      "          8.3984e-02, -8.8578e-02,  8.0181e-02,  6.5689e-02,  7.8271e-03,\n",
      "         -9.1994e-02,  6.6988e-03, -9.1188e-02, -1.4394e-02, -7.1553e-02,\n",
      "         -4.5837e-02,  6.1813e-03,  7.9895e-02, -1.9126e-02,  8.1019e-04,\n",
      "         -8.0004e-03, -9.5591e-02, -6.7938e-02,  6.3850e-02, -5.3796e-02,\n",
      "          9.8376e-02,  8.6002e-03,  4.2810e-02, -7.9046e-02,  7.5679e-02,\n",
      "          5.7380e-02,  2.6522e-02, -5.6602e-02, -2.3860e-02, -3.2694e-02,\n",
      "          3.3661e-03,  3.3369e-02, -2.6131e-02,  4.1486e-02, -2.4446e-02,\n",
      "          9.6503e-02, -5.4718e-02,  8.7951e-02,  4.1143e-02, -3.2901e-02,\n",
      "          9.9015e-02, -3.5997e-03, -3.4025e-03, -1.7800e-02,  6.0875e-02,\n",
      "         -2.8876e-02,  3.9300e-02, -7.8853e-02,  8.6979e-02,  7.3574e-02,\n",
      "         -4.1438e-02,  7.5618e-02, -7.5304e-02, -3.4147e-03,  7.0915e-02,\n",
      "         -4.9581e-03,  5.6163e-02, -3.9791e-02, -9.9715e-02, -4.1026e-03,\n",
      "          7.4236e-02,  5.5314e-02, -6.9833e-02, -9.5531e-02,  4.4018e-02,\n",
      "          4.5934e-02,  1.8303e-02, -7.7866e-02,  7.2832e-02,  3.8321e-03,\n",
      "         -3.2310e-02, -3.0326e-02, -7.6570e-02, -3.2393e-02, -7.6507e-02,\n",
      "          2.7752e-03,  9.2013e-02, -3.8422e-02,  1.5726e-02, -3.6031e-02],\n",
      "        [-4.2809e-02,  9.3418e-02,  8.5998e-02, -8.2695e-02,  8.4872e-02,\n",
      "         -4.7598e-02, -1.5656e-02, -3.0391e-03, -7.8345e-02, -1.0491e-02,\n",
      "         -8.6830e-02, -4.4549e-02, -5.4298e-02,  3.4726e-02, -7.2646e-02,\n",
      "         -1.1978e-02,  6.2996e-02, -5.3038e-02, -3.2611e-02, -1.3622e-02,\n",
      "         -8.0636e-02, -4.0322e-02, -2.5070e-02, -5.0331e-02,  6.6102e-02,\n",
      "          3.8139e-02, -3.5299e-02,  1.0892e-02,  5.3209e-02, -5.3694e-02,\n",
      "          3.3962e-02,  5.4020e-02, -5.4706e-02,  2.5151e-02, -4.4926e-02,\n",
      "         -8.8154e-02,  2.8000e-02,  4.3376e-02,  2.4858e-02, -3.0191e-02,\n",
      "         -5.4838e-02,  2.1992e-02, -2.3021e-02, -1.9184e-02, -5.6297e-02,\n",
      "         -4.2148e-02,  4.6704e-02, -1.3622e-02,  5.3570e-02,  9.5940e-02,\n",
      "         -8.6381e-02,  3.4196e-02, -2.1907e-02,  9.6421e-02,  5.8558e-02,\n",
      "          5.4537e-02, -5.8824e-02, -7.9939e-02,  2.6643e-03, -4.0186e-02,\n",
      "         -8.2115e-02, -3.2209e-02, -8.1563e-02,  8.3376e-02, -5.2503e-02,\n",
      "          6.9394e-02, -5.9260e-02, -6.3681e-02, -4.5775e-02,  9.5779e-02,\n",
      "         -8.9759e-02,  8.4587e-03,  6.0631e-02, -5.7599e-02,  6.8412e-03,\n",
      "         -6.3244e-02, -6.3762e-02, -4.6935e-02, -2.6984e-02,  4.3818e-02,\n",
      "          8.8496e-02,  2.4446e-02, -1.0030e-02,  3.2385e-02, -1.9681e-02,\n",
      "          4.8239e-02,  8.7874e-02, -2.6989e-02, -3.2352e-03,  7.1018e-02,\n",
      "         -9.4258e-03, -9.4267e-02,  4.9120e-02,  3.2491e-02,  5.4577e-02,\n",
      "          6.0579e-02,  2.4154e-04,  3.7269e-02,  3.7370e-02, -1.6724e-02],\n",
      "        [-4.4582e-02, -9.4577e-02, -6.8956e-02, -8.7897e-02,  4.4615e-02,\n",
      "          2.3344e-02, -6.9625e-02,  8.7126e-02,  3.0823e-02,  7.3412e-02,\n",
      "         -6.5325e-02,  6.6556e-03,  5.4836e-02,  3.3985e-02,  4.6642e-02,\n",
      "         -2.7303e-02, -6.9832e-02, -1.3864e-02,  9.9051e-02, -2.5077e-02,\n",
      "         -4.4494e-02, -3.7682e-02, -8.1260e-02,  1.5018e-02,  3.5875e-02,\n",
      "          3.4807e-02, -2.1883e-02,  7.0419e-02, -5.0020e-02, -1.8996e-02,\n",
      "          6.7029e-02, -5.3086e-03,  3.0149e-03,  5.2770e-02, -6.4053e-03,\n",
      "          2.3478e-02, -5.5279e-02, -4.9624e-03, -8.8719e-03, -4.1304e-02,\n",
      "          7.1579e-02, -3.7593e-02, -6.0884e-02,  6.7667e-02,  6.3293e-02,\n",
      "         -5.7820e-02,  5.4275e-02, -1.8266e-02, -3.4324e-02, -2.3063e-02,\n",
      "          6.8039e-02, -4.3113e-02,  1.3769e-02,  4.6547e-02,  2.7215e-02,\n",
      "         -7.8149e-02,  3.4554e-02, -7.0489e-02,  9.1348e-03, -7.7060e-02,\n",
      "          7.1846e-02,  3.0306e-02, -6.1545e-02, -2.7564e-02,  7.3886e-02,\n",
      "         -5.9818e-02,  5.9650e-02,  6.5562e-02,  4.0175e-02, -9.5528e-02,\n",
      "         -8.4671e-02,  8.9506e-02, -1.0494e-02, -4.6461e-03, -2.3212e-02,\n",
      "         -6.0118e-02, -1.1317e-02, -4.2227e-02, -3.3702e-02, -4.1652e-02,\n",
      "          7.4687e-02, -2.9645e-02, -3.5168e-02,  8.1746e-02,  6.3201e-02,\n",
      "          8.2489e-02,  6.6744e-02, -9.2885e-03,  3.8179e-02, -9.6297e-02,\n",
      "         -3.6300e-02, -7.0654e-02,  1.9282e-02,  5.0511e-02, -2.3786e-02,\n",
      "         -7.6305e-03, -7.5311e-02, -8.4680e-02,  8.5115e-02,  1.1903e-02],\n",
      "        [ 8.8173e-02,  2.7937e-02, -4.9321e-02, -3.5425e-02,  9.6030e-02,\n",
      "          8.4402e-02, -1.4313e-02, -6.5185e-02, -6.0675e-02, -6.3354e-03,\n",
      "         -1.5803e-02, -6.1468e-02,  1.9881e-02,  4.5379e-02, -8.8415e-02,\n",
      "         -6.1101e-02,  6.9037e-02,  9.3889e-02, -1.1827e-02, -9.0557e-02,\n",
      "         -9.4272e-02,  3.6580e-02,  6.0235e-02, -7.3008e-02,  4.2090e-02,\n",
      "         -4.0497e-03, -4.9899e-02, -8.1717e-02, -6.8638e-02, -8.9444e-02,\n",
      "          4.5182e-02, -7.6639e-02, -4.0385e-02, -3.3123e-02, -1.1410e-02,\n",
      "          9.0826e-02, -7.7282e-02,  7.0562e-02,  9.0649e-02,  5.3056e-02,\n",
      "         -7.4187e-02, -5.4747e-02,  3.1456e-03,  1.6454e-02, -9.0918e-02,\n",
      "          3.7263e-02, -2.1833e-02,  5.8672e-02,  4.7486e-02,  5.0141e-02,\n",
      "          6.2007e-02, -5.6279e-02,  8.5555e-02,  6.8694e-02, -7.9228e-02,\n",
      "         -5.7107e-02, -7.2981e-02, -5.0564e-02, -4.9943e-02, -1.0018e-02,\n",
      "          2.9700e-02,  2.9274e-02, -1.1256e-02,  7.8468e-02,  1.9917e-02,\n",
      "          8.3517e-02, -3.7203e-02,  3.4996e-02,  3.0142e-02,  7.2039e-02,\n",
      "         -8.5470e-02,  3.4698e-02, -2.4628e-02, -5.7621e-02,  8.0619e-02,\n",
      "          4.1994e-02,  1.8419e-02, -6.6855e-02, -7.1815e-03, -9.7656e-02,\n",
      "         -7.6045e-02, -8.9471e-02,  1.8276e-02,  4.6263e-02, -9.6497e-02,\n",
      "         -7.3275e-02,  8.0950e-02, -6.5101e-02,  1.9448e-02, -7.5553e-03,\n",
      "         -4.3875e-02,  3.7131e-03,  9.2268e-02, -2.8359e-02,  7.3117e-02,\n",
      "          2.8109e-02,  7.8418e-02,  2.2319e-02,  8.0144e-02, -6.3643e-02]])), ('linear3.bias', tensor([ 0.0643, -0.0388,  0.0781,  0.0300,  0.0928, -0.0030, -0.0584, -0.0098,\n",
      "         0.0117, -0.0322]))])\n",
      "Net_A1_DT: \n",
      " \t OrderedDict([('conv1.weight', tensor([[[[-0.2883,  0.1564,  0.1609],\n",
      "          [-0.0444, -0.0949, -0.3182],\n",
      "          [ 0.2915,  0.3080,  0.2105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1010,  0.2522,  0.2758],\n",
      "          [ 0.2323,  0.2154,  0.2896],\n",
      "          [-0.2110, -0.0941, -0.2463]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2065,  0.2438, -0.1999],\n",
      "          [ 0.0054,  0.0993, -0.0013],\n",
      "          [-0.0640,  0.0031,  0.0364]]],\n",
      "\n",
      "\n",
      "        [[[-0.1630,  0.0651, -0.3326],\n",
      "          [ 0.1536,  0.0603,  0.2092],\n",
      "          [-0.3016,  0.1574,  0.1269]]]])), ('conv1.bias', tensor([ 0.1892, -0.2638,  0.0942, -0.1126])), ('conv2.weight', tensor([[[[ 0.0277,  0.1149, -0.1208],\n",
      "          [ 0.1161,  0.1605, -0.0957],\n",
      "          [-0.1079, -0.1183, -0.0668]],\n",
      "\n",
      "         [[-0.1547, -0.0691, -0.1027],\n",
      "          [-0.0794, -0.0236,  0.0004],\n",
      "          [-0.0838,  0.0406, -0.0066]],\n",
      "\n",
      "         [[ 0.0825, -0.1004,  0.0103],\n",
      "          [ 0.0283,  0.0741, -0.0702],\n",
      "          [-0.0884,  0.0566, -0.1151]],\n",
      "\n",
      "         [[ 0.0678,  0.1228, -0.0446],\n",
      "          [ 0.1102,  0.0567, -0.1177],\n",
      "          [-0.0948,  0.1466,  0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0481, -0.1236, -0.0548],\n",
      "          [-0.1211,  0.0455, -0.0900],\n",
      "          [-0.0881, -0.0630,  0.0127]],\n",
      "\n",
      "         [[-0.0302, -0.0815, -0.0060],\n",
      "          [-0.1386, -0.0463,  0.0019],\n",
      "          [-0.0203, -0.0756,  0.0394]],\n",
      "\n",
      "         [[ 0.0220,  0.0737,  0.0375],\n",
      "          [ 0.1448, -0.0480,  0.0053],\n",
      "          [-0.0264, -0.1254,  0.0408]],\n",
      "\n",
      "         [[-0.1433, -0.0717, -0.1519],\n",
      "          [-0.0284,  0.0483,  0.1254],\n",
      "          [ 0.1048, -0.1471, -0.0192]]],\n",
      "\n",
      "\n",
      "        [[[-0.1214, -0.0114, -0.0650],\n",
      "          [ 0.0441,  0.1437, -0.0815],\n",
      "          [-0.1046,  0.1386, -0.0093]],\n",
      "\n",
      "         [[-0.1239,  0.0977,  0.1428],\n",
      "          [-0.0667,  0.0277, -0.1622],\n",
      "          [-0.0084, -0.1623, -0.0426]],\n",
      "\n",
      "         [[-0.0744, -0.0416, -0.0755],\n",
      "          [ 0.1014, -0.0479,  0.1453],\n",
      "          [ 0.1127,  0.0843,  0.1025]],\n",
      "\n",
      "         [[-0.1527,  0.0352,  0.0479],\n",
      "          [-0.0681, -0.1173, -0.1619],\n",
      "          [ 0.1134, -0.1410,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1035,  0.1176, -0.1514],\n",
      "          [-0.0786, -0.0893, -0.0645],\n",
      "          [ 0.0692,  0.0216,  0.0929]],\n",
      "\n",
      "         [[ 0.0940,  0.0771, -0.0682],\n",
      "          [-0.0937,  0.1657,  0.0603],\n",
      "          [-0.0226, -0.0135, -0.0929]],\n",
      "\n",
      "         [[ 0.0138, -0.1619,  0.0119],\n",
      "          [ 0.0873,  0.0704, -0.1510],\n",
      "          [ 0.1643, -0.0898, -0.1235]],\n",
      "\n",
      "         [[-0.0768,  0.1207, -0.0881],\n",
      "          [-0.0107, -0.1406,  0.0444],\n",
      "          [-0.0925, -0.1311,  0.0439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1248,  0.0391,  0.1382],\n",
      "          [-0.1300, -0.0065, -0.1247],\n",
      "          [ 0.0092,  0.0483,  0.0728]],\n",
      "\n",
      "         [[-0.0111, -0.1385, -0.0405],\n",
      "          [ 0.0897, -0.1337,  0.0845],\n",
      "          [ 0.0412,  0.1241,  0.1158]],\n",
      "\n",
      "         [[-0.0636, -0.1513, -0.1154],\n",
      "          [ 0.0560, -0.0266,  0.1168],\n",
      "          [-0.0036, -0.1158, -0.0499]],\n",
      "\n",
      "         [[-0.0608,  0.0503, -0.0282],\n",
      "          [ 0.1367, -0.0551, -0.0871],\n",
      "          [-0.0443,  0.1156, -0.0237]]],\n",
      "\n",
      "\n",
      "        [[[-0.0578,  0.1307,  0.1498],\n",
      "          [ 0.1168,  0.1255, -0.0361],\n",
      "          [ 0.0610,  0.0237,  0.0126]],\n",
      "\n",
      "         [[-0.1344,  0.0685, -0.1344],\n",
      "          [ 0.1060,  0.1278,  0.1221],\n",
      "          [-0.0153, -0.1446, -0.1478]],\n",
      "\n",
      "         [[ 0.1608,  0.0608, -0.1501],\n",
      "          [ 0.0874, -0.0374, -0.1175],\n",
      "          [ 0.1032,  0.1281,  0.0354]],\n",
      "\n",
      "         [[-0.0255, -0.0660, -0.1522],\n",
      "          [ 0.1521, -0.0384,  0.1535],\n",
      "          [ 0.0805,  0.1001,  0.0620]]]])), ('conv2.bias', tensor([ 0.1004,  0.0124, -0.1523, -0.0778, -0.1434,  0.1143])), ('linear1.weight', tensor([[-0.0275,  0.0443,  0.0005,  ..., -0.0383,  0.0138, -0.0651],\n",
      "        [ 0.0233, -0.0665, -0.0592,  ...,  0.0673, -0.0275, -0.0332],\n",
      "        [ 0.0632,  0.0485, -0.0634,  ..., -0.0548,  0.0289, -0.0629],\n",
      "        ...,\n",
      "        [ 0.0778,  0.0472, -0.0498,  ..., -0.0364,  0.0123,  0.0035],\n",
      "        [-0.0745,  0.0345, -0.0013,  ...,  0.0689, -0.0481, -0.0798],\n",
      "        [ 0.0390, -0.0745, -0.0550,  ...,  0.0629,  0.0341, -0.0304]])), ('linear1.bias', tensor([-0.0615, -0.0117,  0.0083, -0.0375, -0.0580,  0.0219, -0.0233, -0.0567,\n",
      "        -0.0102, -0.0006,  0.0032,  0.0647, -0.0771,  0.0072,  0.0516,  0.0269,\n",
      "        -0.0402, -0.0172, -0.0466, -0.0546, -0.0268, -0.0388, -0.0094,  0.0358,\n",
      "        -0.0276,  0.0461,  0.0257,  0.0505,  0.0458,  0.0628,  0.0648, -0.0669,\n",
      "        -0.0587,  0.0765, -0.0807, -0.0726, -0.0490, -0.0641,  0.0527, -0.0764,\n",
      "         0.0208,  0.0653, -0.0799,  0.0142,  0.0747,  0.0797, -0.0318, -0.0208,\n",
      "        -0.0451,  0.0541,  0.0603,  0.0626,  0.0525, -0.0668, -0.0755, -0.0148,\n",
      "        -0.0544, -0.0346, -0.0522, -0.0331, -0.0085, -0.0209,  0.0567,  0.0244,\n",
      "        -0.0542, -0.0250, -0.0556,  0.0445,  0.0544, -0.0008,  0.0119,  0.0752,\n",
      "         0.0406,  0.0255, -0.0497,  0.0692,  0.0801, -0.0405, -0.0339,  0.0262,\n",
      "        -0.0640, -0.0108,  0.0157,  0.0221,  0.0672,  0.0356, -0.0687, -0.0281,\n",
      "         0.0106, -0.0533,  0.0336,  0.0470, -0.0289, -0.0344,  0.0392,  0.0199,\n",
      "        -0.0141, -0.0644,  0.0807, -0.0422,  0.0643,  0.0413, -0.0112,  0.0028,\n",
      "         0.0056,  0.0735, -0.0429,  0.0387, -0.0054, -0.0104,  0.0050,  0.0644,\n",
      "        -0.0451, -0.0361, -0.0785,  0.0084,  0.0092, -0.0086, -0.0058, -0.0072,\n",
      "         0.0490,  0.0569, -0.0599, -0.0766, -0.0016,  0.0697, -0.0089,  0.0085,\n",
      "        -0.0793,  0.0716, -0.0429, -0.0049, -0.0233,  0.0079,  0.0648,  0.0540,\n",
      "         0.0709,  0.0621,  0.0129, -0.0701,  0.0108,  0.0731, -0.0100,  0.0446,\n",
      "        -0.0181, -0.0555, -0.0652,  0.0438, -0.0628, -0.0811,  0.0021, -0.0611,\n",
      "        -0.0746,  0.0447, -0.0587, -0.0036,  0.0541,  0.0742,  0.0734,  0.0328,\n",
      "        -0.0321,  0.0366,  0.0319, -0.0816, -0.0667, -0.0555, -0.0042,  0.0107,\n",
      "        -0.0726, -0.0246, -0.0160,  0.0660,  0.0510,  0.0803,  0.0362, -0.0045,\n",
      "        -0.0705,  0.0591,  0.0207,  0.0616,  0.0517, -0.0787, -0.0007,  0.0347,\n",
      "        -0.0181,  0.0245,  0.0405,  0.0607,  0.0520, -0.0273, -0.0172, -0.0714,\n",
      "        -0.0248,  0.0163,  0.0454,  0.0308,  0.0010,  0.0378,  0.0815, -0.0750])), ('linear2.weight', tensor([[-0.0042, -0.0664, -0.0118,  ...,  0.0148, -0.0284,  0.0039],\n",
      "        [-0.0452,  0.0207,  0.0591,  ..., -0.0684, -0.0238,  0.0260],\n",
      "        [-0.0437,  0.0180,  0.0477,  ...,  0.0199, -0.0060, -0.0195],\n",
      "        ...,\n",
      "        [-0.0451,  0.0539,  0.0370,  ...,  0.0321,  0.0120,  0.0387],\n",
      "        [ 0.0475, -0.0599,  0.0200,  ..., -0.0546, -0.0012,  0.0291],\n",
      "        [ 0.0478, -0.0036, -0.0543,  ...,  0.0015, -0.0565,  0.0521]])), ('linear2.bias', tensor([-0.0103,  0.0295, -0.0524,  0.0209, -0.0312,  0.0028,  0.0680, -0.0655,\n",
      "        -0.0520,  0.0149, -0.0618,  0.0181, -0.0420,  0.0538,  0.0425, -0.0481,\n",
      "        -0.0220,  0.0223,  0.0516, -0.0697, -0.0291, -0.0276, -0.0583,  0.0142,\n",
      "         0.0250,  0.0228, -0.0127,  0.0575,  0.0518, -0.0053,  0.0385,  0.0021,\n",
      "         0.0387, -0.0391, -0.0334,  0.0156, -0.0209,  0.0030,  0.0457,  0.0301,\n",
      "        -0.0045,  0.0592, -0.0544,  0.0390, -0.0016,  0.0403, -0.0634,  0.0468,\n",
      "         0.0444,  0.0669,  0.0402, -0.0063,  0.0045, -0.0096,  0.0641, -0.0079,\n",
      "         0.0208,  0.0011,  0.0692,  0.0317, -0.0565,  0.0250, -0.0683,  0.0495,\n",
      "        -0.0664, -0.0450, -0.0109,  0.0369,  0.0547,  0.0643,  0.0341,  0.0659,\n",
      "        -0.0308, -0.0601, -0.0285,  0.0253,  0.0024,  0.0445,  0.0065,  0.0104,\n",
      "         0.0254, -0.0333,  0.0102, -0.0249, -0.0065, -0.0134,  0.0039, -0.0404,\n",
      "         0.0048,  0.0044, -0.0227,  0.0635,  0.0332, -0.0635, -0.0600, -0.0027,\n",
      "         0.0532, -0.0278,  0.0502, -0.0239])), ('linear3.weight', tensor([[-8.1859e-02,  5.4963e-02, -5.6116e-02, -8.6450e-02, -7.9618e-02,\n",
      "         -8.4659e-02, -3.4566e-02,  8.4525e-02,  8.7622e-02,  6.5951e-02,\n",
      "          2.6708e-02,  3.5574e-02, -6.0221e-03,  8.0275e-02, -6.1368e-02,\n",
      "          4.9290e-03,  3.5392e-02, -2.2645e-02,  4.4268e-02, -8.0110e-02,\n",
      "          1.4589e-02,  3.0174e-02,  2.8925e-02, -8.2486e-02, -2.5872e-02,\n",
      "          7.1676e-02,  2.6952e-02, -1.0749e-02, -5.6320e-02, -8.6459e-02,\n",
      "         -8.6584e-02, -5.4351e-02,  2.8330e-02, -2.1272e-02, -3.4326e-02,\n",
      "         -5.0077e-02,  2.4330e-02, -8.5856e-02, -3.6957e-02,  7.9977e-02,\n",
      "          9.6991e-02,  8.2000e-02,  9.6424e-02, -2.0202e-02,  9.6164e-02,\n",
      "         -7.6048e-02, -9.7211e-02, -8.4153e-02,  9.0702e-02, -1.5679e-03,\n",
      "         -2.0085e-02,  5.8475e-02, -5.4412e-02,  3.9156e-02,  3.3173e-02,\n",
      "          7.8190e-02, -8.9351e-02,  2.7967e-02, -5.2699e-02, -4.5874e-02,\n",
      "          4.4745e-02, -3.4582e-02,  2.5797e-02,  3.3519e-02, -5.4114e-02,\n",
      "          2.6085e-02,  6.4530e-02,  6.0624e-02,  9.4019e-02,  8.4863e-02,\n",
      "         -8.8824e-03, -7.7267e-02,  3.8065e-02,  7.8011e-02, -3.8461e-02,\n",
      "         -6.5697e-02,  1.2262e-02,  4.9022e-02,  1.2675e-02,  8.6289e-02,\n",
      "          6.7781e-02,  4.9048e-02, -5.3796e-02,  4.6017e-02, -7.0453e-02,\n",
      "         -1.0496e-02,  5.5595e-02, -2.7439e-02, -5.2598e-02,  1.3613e-02,\n",
      "          3.0768e-02,  1.5250e-02, -2.3559e-02,  2.3216e-02,  8.2579e-02,\n",
      "         -1.8082e-02,  3.2377e-02, -7.7281e-02,  5.8582e-02, -5.6018e-03],\n",
      "        [-2.1737e-03,  4.9144e-02,  8.5194e-02,  8.3546e-03,  5.2413e-02,\n",
      "          6.1892e-02, -6.5699e-02,  9.7719e-02, -9.6838e-02,  8.5933e-02,\n",
      "          6.6142e-02, -7.8098e-03,  8.5373e-02, -8.0669e-02,  4.8838e-02,\n",
      "          1.6007e-02,  2.3221e-02, -2.4227e-02,  9.2616e-02, -4.7297e-02,\n",
      "         -4.7309e-02, -3.6943e-04,  6.3139e-02, -8.0873e-02,  7.2832e-02,\n",
      "         -5.8740e-02,  9.6004e-02,  6.8465e-02,  1.9791e-02,  5.1360e-02,\n",
      "          7.3122e-02, -5.8274e-02,  9.7646e-02, -5.5470e-02,  1.6590e-02,\n",
      "         -5.6363e-02,  1.6818e-02, -3.7351e-02, -6.9838e-02, -4.6850e-02,\n",
      "         -1.2686e-02,  2.1933e-02, -2.1890e-02, -7.2976e-02,  8.5696e-02,\n",
      "          6.6278e-02, -3.1678e-02,  5.3716e-02, -4.1456e-02,  7.0112e-02,\n",
      "          1.7500e-03, -8.2864e-02,  1.1726e-02, -4.4551e-02,  6.1122e-02,\n",
      "         -8.6927e-02, -4.3267e-02,  1.9693e-02,  8.1164e-02,  2.6885e-02,\n",
      "          2.2644e-03,  5.2035e-02, -6.9280e-02,  9.4441e-02,  2.4128e-02,\n",
      "         -4.0068e-02,  7.8931e-02, -4.0139e-02, -4.9139e-02,  1.6601e-02,\n",
      "         -4.7312e-02,  6.6093e-02, -5.8181e-02, -8.6935e-02, -8.1730e-02,\n",
      "          2.3250e-03, -2.0783e-02, -4.8774e-02, -3.2974e-02,  9.1256e-02,\n",
      "          6.4540e-02,  6.0788e-02, -8.4923e-03,  7.0240e-02, -9.1425e-02,\n",
      "          1.4017e-02, -6.2668e-02,  3.6186e-03, -3.2159e-03, -9.8639e-02,\n",
      "         -2.4306e-02, -1.2926e-02, -1.1208e-02, -1.1007e-02,  7.8119e-02,\n",
      "          6.9694e-02,  7.6771e-02, -6.4797e-02, -8.8241e-02, -2.6725e-02],\n",
      "        [-4.6950e-02, -5.7878e-02, -4.2660e-02,  9.6962e-03,  5.0218e-02,\n",
      "          9.1794e-02, -9.1601e-02, -4.0121e-02,  2.6923e-02,  7.5591e-02,\n",
      "         -1.7488e-02, -4.9651e-02, -2.0451e-02, -1.3599e-02,  4.1437e-02,\n",
      "          7.1272e-02,  9.8382e-02,  4.9390e-02, -3.9955e-02, -1.1288e-02,\n",
      "          4.6374e-02, -7.7535e-02, -5.8219e-02,  6.1845e-02,  5.8048e-02,\n",
      "          1.8745e-02,  3.5735e-02, -6.5009e-02, -9.0972e-03,  8.0850e-02,\n",
      "          3.5748e-02, -5.1905e-02, -7.6213e-02, -2.7620e-02,  9.1213e-03,\n",
      "         -6.5099e-02,  6.7302e-02, -8.6544e-02,  5.0261e-02, -8.6582e-02,\n",
      "          7.2538e-02, -7.3985e-02, -3.2245e-03, -3.5631e-02, -8.1305e-02,\n",
      "         -1.2679e-02,  7.3839e-02, -5.7263e-02, -2.8822e-02,  9.6337e-04,\n",
      "          6.7876e-02, -8.5426e-02,  1.2920e-02, -1.2081e-02,  9.6181e-02,\n",
      "         -3.1630e-03, -9.9101e-02, -3.9246e-02, -6.3765e-02,  2.1755e-02,\n",
      "         -4.0034e-02,  7.2982e-02,  2.8868e-02, -4.9884e-02, -8.3014e-02,\n",
      "         -4.7947e-03,  9.7719e-02,  7.8436e-02, -9.8796e-03, -6.0552e-02,\n",
      "         -9.4831e-02, -1.2137e-02,  1.7098e-02,  4.1281e-02, -3.8697e-02,\n",
      "          8.1316e-02, -4.3466e-02,  3.1320e-02,  7.8142e-02,  2.1996e-02,\n",
      "          6.1583e-02,  3.6209e-02, -8.1611e-02, -4.0207e-02,  9.7864e-02,\n",
      "         -9.4649e-02, -7.6439e-02,  5.8250e-02, -6.1609e-02,  1.7509e-02,\n",
      "          8.5045e-02,  7.2830e-02, -3.8142e-02, -5.2286e-03,  3.7451e-02,\n",
      "          4.6779e-02,  2.6209e-02, -2.3014e-02, -7.2745e-02,  8.5597e-02],\n",
      "        [ 4.1696e-02,  4.4693e-02,  6.1973e-02, -9.9138e-03,  5.5230e-02,\n",
      "         -8.6240e-02,  1.6320e-02,  1.9276e-02,  4.6386e-02, -6.1514e-02,\n",
      "          6.4261e-02,  9.1878e-02, -6.6806e-02, -6.8039e-02, -1.1481e-02,\n",
      "          9.5905e-02, -9.8847e-02,  6.1363e-02, -6.6134e-02, -4.1346e-02,\n",
      "         -7.0979e-02, -4.8980e-02, -1.0452e-02,  9.5735e-03, -3.2604e-02,\n",
      "          2.2604e-02, -1.9193e-05,  4.8956e-02, -3.7671e-03,  7.6825e-02,\n",
      "          1.1480e-04,  9.3519e-02,  2.7575e-02,  3.2067e-02, -6.7589e-02,\n",
      "         -6.0556e-02,  2.5333e-02, -5.8154e-02,  1.8586e-02,  8.8252e-02,\n",
      "         -3.5308e-02, -6.5909e-02, -9.9277e-02, -2.2356e-02,  3.8486e-02,\n",
      "         -9.9173e-02,  7.8653e-02,  9.4884e-02, -1.6012e-02,  6.0038e-02,\n",
      "          6.4644e-02,  2.1986e-02,  6.3920e-02, -2.3612e-02, -5.1584e-02,\n",
      "          3.3839e-02,  6.3053e-02,  8.8806e-02,  6.1454e-02, -2.2593e-02,\n",
      "         -4.2546e-02,  7.3978e-02, -5.7074e-03,  7.6196e-02,  6.9998e-02,\n",
      "         -4.5981e-02,  1.3264e-02, -9.0404e-02, -4.2183e-02,  4.2104e-02,\n",
      "         -4.7168e-02, -1.4863e-03,  8.4832e-05,  3.0544e-02, -5.1999e-02,\n",
      "          9.6292e-02, -7.3996e-02, -5.1649e-02, -1.0851e-02,  6.0104e-02,\n",
      "          6.4677e-02,  9.2728e-02, -8.7749e-02, -9.2763e-02,  6.8107e-02,\n",
      "         -9.2449e-02, -9.1984e-02, -6.3421e-02, -4.8753e-02, -5.0742e-02,\n",
      "          8.6135e-03,  1.1766e-02, -9.2633e-02,  2.7062e-02, -1.8486e-02,\n",
      "          5.4209e-02,  7.6607e-02, -1.5315e-02,  1.8004e-02, -4.0003e-02],\n",
      "        [ 6.6454e-02,  5.5929e-02,  7.2999e-02,  3.9813e-02, -8.3831e-02,\n",
      "          7.3774e-03, -3.6408e-02, -8.4750e-02,  7.8808e-02, -8.4615e-02,\n",
      "          2.5438e-02,  5.3372e-02,  8.0464e-02, -6.1655e-02, -1.7745e-02,\n",
      "          9.7800e-02, -4.8533e-02, -1.6866e-02,  6.0858e-02,  7.9891e-02,\n",
      "         -4.2657e-02,  7.1293e-02,  6.4880e-02,  6.7515e-02, -9.9129e-02,\n",
      "         -4.6123e-02,  3.8089e-02,  7.0895e-02, -8.7748e-03,  5.8277e-02,\n",
      "         -4.9671e-02, -1.3719e-03, -3.0569e-02, -1.1523e-02,  2.0952e-02,\n",
      "          2.2758e-02,  9.2663e-02,  7.5245e-02,  6.0371e-02, -4.2461e-02,\n",
      "         -9.7548e-02, -7.2743e-02,  9.0799e-02, -6.7926e-02,  3.4070e-02,\n",
      "         -5.9770e-02, -9.1988e-02, -9.6402e-02,  5.9512e-02,  6.0051e-02,\n",
      "          4.5341e-02,  3.7750e-02, -6.3905e-02,  7.6300e-02,  4.4272e-02,\n",
      "         -3.7506e-02,  9.2099e-02, -8.7454e-02,  9.0623e-02,  5.1123e-02,\n",
      "         -8.7771e-02, -2.7548e-02, -4.0736e-02, -7.2736e-02,  3.7171e-02,\n",
      "          9.8917e-03,  5.2082e-02, -7.6377e-02, -6.6851e-02, -3.1641e-02,\n",
      "         -7.1990e-03, -4.6810e-02,  3.4162e-02, -6.0850e-02, -7.7988e-02,\n",
      "          4.7929e-02, -4.9367e-02,  5.4005e-02,  3.2642e-02, -7.2771e-02,\n",
      "         -7.8209e-02,  1.5981e-03, -8.9771e-02, -3.6514e-02, -8.2809e-02,\n",
      "         -2.8809e-02, -4.0658e-02, -7.9969e-02,  1.3079e-02,  9.4315e-02,\n",
      "          8.1098e-02,  1.4628e-02,  7.6222e-02,  7.5831e-02,  8.9282e-02,\n",
      "          8.9975e-02,  8.8806e-03, -6.6194e-02, -9.2579e-02, -8.0210e-02],\n",
      "        [ 9.0424e-02, -7.0654e-02,  1.5695e-02, -3.0525e-03,  3.2655e-02,\n",
      "          8.1709e-02,  4.8581e-02, -8.5740e-02,  7.0387e-02,  2.0039e-02,\n",
      "         -9.3993e-03,  6.1952e-02, -7.5213e-02, -2.0438e-02,  7.7954e-02,\n",
      "         -5.6431e-02,  1.7378e-02, -6.5140e-02,  9.0492e-02,  7.4408e-02,\n",
      "         -8.2079e-02,  3.7301e-02,  4.1933e-02,  2.0768e-03, -9.9183e-02,\n",
      "          3.5526e-02,  1.7915e-02, -1.4981e-03, -5.6192e-02, -6.3391e-02,\n",
      "          5.4214e-02,  1.9851e-02,  7.0704e-02,  5.5143e-02, -9.4359e-02,\n",
      "         -2.0447e-02, -5.4021e-02, -1.7544e-02,  3.1014e-02,  2.0043e-02,\n",
      "         -5.3172e-02,  9.0788e-02, -9.1185e-02, -3.2232e-02, -4.7469e-03,\n",
      "         -2.8208e-02, -7.6272e-02,  1.3877e-02,  4.2906e-02,  2.5806e-02,\n",
      "         -8.5831e-02, -3.2161e-03,  4.8048e-02,  2.3483e-02, -5.5108e-02,\n",
      "          9.5038e-02, -6.8033e-02,  2.8781e-02,  5.3509e-02,  1.1501e-02,\n",
      "         -3.9263e-02,  8.7513e-02, -5.2261e-02, -1.3199e-02, -8.9100e-02,\n",
      "          5.7819e-02, -1.0709e-02, -9.5532e-02,  2.2298e-02, -3.5143e-02,\n",
      "         -6.1559e-02,  4.6720e-02, -6.7011e-02,  9.2027e-02, -4.3895e-02,\n",
      "          9.0376e-03, -5.7872e-02, -6.8063e-02,  8.3585e-02,  9.3695e-02,\n",
      "         -2.8009e-02,  1.8826e-02, -7.6306e-02, -3.8887e-02,  6.5648e-02,\n",
      "         -6.9703e-02, -9.7531e-02,  2.4369e-02,  8.2048e-02,  3.1030e-02,\n",
      "          6.5589e-02, -2.2381e-02, -5.5507e-02,  3.6555e-02, -6.5690e-02,\n",
      "          2.9737e-02,  8.5040e-02, -8.1627e-02,  5.9282e-02,  7.2390e-02],\n",
      "        [ 4.0002e-02, -1.9877e-02,  4.3460e-02, -5.5065e-02,  4.3808e-02,\n",
      "          4.7897e-02, -4.5228e-02, -5.4103e-02,  1.9917e-02,  6.3860e-02,\n",
      "          3.3037e-02, -7.0828e-02, -9.6749e-02,  7.1200e-02,  6.5551e-02,\n",
      "         -4.7477e-02,  6.3970e-02, -9.6249e-02, -9.9156e-02, -5.8389e-02,\n",
      "          8.3984e-02, -8.8578e-02,  8.0181e-02,  6.5689e-02,  7.8271e-03,\n",
      "         -9.1994e-02,  6.6988e-03, -9.1188e-02, -1.4394e-02, -7.1553e-02,\n",
      "         -4.5837e-02,  6.1813e-03,  7.9895e-02, -1.9126e-02,  8.1019e-04,\n",
      "         -8.0004e-03, -9.5591e-02, -6.7938e-02,  6.3850e-02, -5.3796e-02,\n",
      "          9.8376e-02,  8.6002e-03,  4.2810e-02, -7.9046e-02,  7.5679e-02,\n",
      "          5.7380e-02,  2.6522e-02, -5.6602e-02, -2.3860e-02, -3.2694e-02,\n",
      "          3.3661e-03,  3.3369e-02, -2.6131e-02,  4.1486e-02, -2.4446e-02,\n",
      "          9.6503e-02, -5.4718e-02,  8.7951e-02,  4.1143e-02, -3.2901e-02,\n",
      "          9.9015e-02, -3.5997e-03, -3.4025e-03, -1.7800e-02,  6.0875e-02,\n",
      "         -2.8876e-02,  3.9300e-02, -7.8853e-02,  8.6979e-02,  7.3574e-02,\n",
      "         -4.1438e-02,  7.5618e-02, -7.5304e-02, -3.4147e-03,  7.0915e-02,\n",
      "         -4.9581e-03,  5.6163e-02, -3.9791e-02, -9.9715e-02, -4.1026e-03,\n",
      "          7.4236e-02,  5.5314e-02, -6.9833e-02, -9.5531e-02,  4.4018e-02,\n",
      "          4.5934e-02,  1.8303e-02, -7.7866e-02,  7.2832e-02,  3.8321e-03,\n",
      "         -3.2310e-02, -3.0326e-02, -7.6570e-02, -3.2393e-02, -7.6507e-02,\n",
      "          2.7752e-03,  9.2013e-02, -3.8422e-02,  1.5726e-02, -3.6031e-02],\n",
      "        [-4.2809e-02,  9.3418e-02,  8.5998e-02, -8.2695e-02,  8.4872e-02,\n",
      "         -4.7598e-02, -1.5656e-02, -3.0391e-03, -7.8345e-02, -1.0491e-02,\n",
      "         -8.6830e-02, -4.4549e-02, -5.4298e-02,  3.4726e-02, -7.2646e-02,\n",
      "         -1.1978e-02,  6.2996e-02, -5.3038e-02, -3.2611e-02, -1.3622e-02,\n",
      "         -8.0636e-02, -4.0322e-02, -2.5070e-02, -5.0331e-02,  6.6102e-02,\n",
      "          3.8139e-02, -3.5299e-02,  1.0892e-02,  5.3209e-02, -5.3694e-02,\n",
      "          3.3962e-02,  5.4020e-02, -5.4706e-02,  2.5151e-02, -4.4926e-02,\n",
      "         -8.8154e-02,  2.8000e-02,  4.3376e-02,  2.4858e-02, -3.0191e-02,\n",
      "         -5.4838e-02,  2.1992e-02, -2.3021e-02, -1.9184e-02, -5.6297e-02,\n",
      "         -4.2148e-02,  4.6704e-02, -1.3622e-02,  5.3570e-02,  9.5940e-02,\n",
      "         -8.6381e-02,  3.4196e-02, -2.1907e-02,  9.6421e-02,  5.8558e-02,\n",
      "          5.4537e-02, -5.8824e-02, -7.9939e-02,  2.6643e-03, -4.0186e-02,\n",
      "         -8.2115e-02, -3.2209e-02, -8.1563e-02,  8.3376e-02, -5.2503e-02,\n",
      "          6.9394e-02, -5.9260e-02, -6.3681e-02, -4.5775e-02,  9.5779e-02,\n",
      "         -8.9759e-02,  8.4587e-03,  6.0631e-02, -5.7599e-02,  6.8412e-03,\n",
      "         -6.3244e-02, -6.3762e-02, -4.6935e-02, -2.6984e-02,  4.3818e-02,\n",
      "          8.8496e-02,  2.4446e-02, -1.0030e-02,  3.2385e-02, -1.9681e-02,\n",
      "          4.8239e-02,  8.7874e-02, -2.6989e-02, -3.2352e-03,  7.1018e-02,\n",
      "         -9.4258e-03, -9.4267e-02,  4.9120e-02,  3.2491e-02,  5.4577e-02,\n",
      "          6.0579e-02,  2.4154e-04,  3.7269e-02,  3.7370e-02, -1.6724e-02],\n",
      "        [-4.4582e-02, -9.4577e-02, -6.8956e-02, -8.7897e-02,  4.4615e-02,\n",
      "          2.3344e-02, -6.9625e-02,  8.7126e-02,  3.0823e-02,  7.3412e-02,\n",
      "         -6.5325e-02,  6.6556e-03,  5.4836e-02,  3.3985e-02,  4.6642e-02,\n",
      "         -2.7303e-02, -6.9832e-02, -1.3864e-02,  9.9051e-02, -2.5077e-02,\n",
      "         -4.4494e-02, -3.7682e-02, -8.1260e-02,  1.5018e-02,  3.5875e-02,\n",
      "          3.4807e-02, -2.1883e-02,  7.0419e-02, -5.0020e-02, -1.8996e-02,\n",
      "          6.7029e-02, -5.3086e-03,  3.0149e-03,  5.2770e-02, -6.4053e-03,\n",
      "          2.3478e-02, -5.5279e-02, -4.9624e-03, -8.8719e-03, -4.1304e-02,\n",
      "          7.1579e-02, -3.7593e-02, -6.0884e-02,  6.7667e-02,  6.3293e-02,\n",
      "         -5.7820e-02,  5.4275e-02, -1.8266e-02, -3.4324e-02, -2.3063e-02,\n",
      "          6.8039e-02, -4.3113e-02,  1.3769e-02,  4.6547e-02,  2.7215e-02,\n",
      "         -7.8149e-02,  3.4554e-02, -7.0489e-02,  9.1348e-03, -7.7060e-02,\n",
      "          7.1846e-02,  3.0306e-02, -6.1545e-02, -2.7564e-02,  7.3886e-02,\n",
      "         -5.9818e-02,  5.9650e-02,  6.5562e-02,  4.0175e-02, -9.5528e-02,\n",
      "         -8.4671e-02,  8.9506e-02, -1.0494e-02, -4.6461e-03, -2.3212e-02,\n",
      "         -6.0118e-02, -1.1317e-02, -4.2227e-02, -3.3702e-02, -4.1652e-02,\n",
      "          7.4687e-02, -2.9645e-02, -3.5168e-02,  8.1746e-02,  6.3201e-02,\n",
      "          8.2489e-02,  6.6744e-02, -9.2885e-03,  3.8179e-02, -9.6297e-02,\n",
      "         -3.6300e-02, -7.0654e-02,  1.9282e-02,  5.0511e-02, -2.3786e-02,\n",
      "         -7.6305e-03, -7.5311e-02, -8.4680e-02,  8.5115e-02,  1.1903e-02],\n",
      "        [ 8.8173e-02,  2.7937e-02, -4.9321e-02, -3.5425e-02,  9.6030e-02,\n",
      "          8.4402e-02, -1.4313e-02, -6.5185e-02, -6.0675e-02, -6.3354e-03,\n",
      "         -1.5803e-02, -6.1468e-02,  1.9881e-02,  4.5379e-02, -8.8415e-02,\n",
      "         -6.1101e-02,  6.9037e-02,  9.3889e-02, -1.1827e-02, -9.0557e-02,\n",
      "         -9.4272e-02,  3.6580e-02,  6.0235e-02, -7.3008e-02,  4.2090e-02,\n",
      "         -4.0497e-03, -4.9899e-02, -8.1717e-02, -6.8638e-02, -8.9444e-02,\n",
      "          4.5182e-02, -7.6639e-02, -4.0385e-02, -3.3123e-02, -1.1410e-02,\n",
      "          9.0826e-02, -7.7282e-02,  7.0562e-02,  9.0649e-02,  5.3056e-02,\n",
      "         -7.4187e-02, -5.4747e-02,  3.1456e-03,  1.6454e-02, -9.0918e-02,\n",
      "          3.7263e-02, -2.1833e-02,  5.8672e-02,  4.7486e-02,  5.0141e-02,\n",
      "          6.2007e-02, -5.6279e-02,  8.5555e-02,  6.8694e-02, -7.9228e-02,\n",
      "         -5.7107e-02, -7.2981e-02, -5.0564e-02, -4.9943e-02, -1.0018e-02,\n",
      "          2.9700e-02,  2.9274e-02, -1.1256e-02,  7.8468e-02,  1.9917e-02,\n",
      "          8.3517e-02, -3.7203e-02,  3.4996e-02,  3.0142e-02,  7.2039e-02,\n",
      "         -8.5470e-02,  3.4698e-02, -2.4628e-02, -5.7621e-02,  8.0619e-02,\n",
      "          4.1994e-02,  1.8419e-02, -6.6855e-02, -7.1815e-03, -9.7656e-02,\n",
      "         -7.6045e-02, -8.9471e-02,  1.8276e-02,  4.6263e-02, -9.6497e-02,\n",
      "         -7.3275e-02,  8.0950e-02, -6.5101e-02,  1.9448e-02, -7.5553e-03,\n",
      "         -4.3875e-02,  3.7131e-03,  9.2268e-02, -2.8359e-02,  7.3117e-02,\n",
      "          2.8109e-02,  7.8418e-02,  2.2319e-02,  8.0144e-02, -6.3643e-02]])), ('linear3.bias', tensor([ 0.0643, -0.0388,  0.0781,  0.0300,  0.0928, -0.0030, -0.0584, -0.0098,\n",
      "         0.0117, -0.0322]))])\n"
     ]
    }
   ],
   "source": [
    "net_a2_hf = NetA2(10, True)\n",
    "net_a2_ht = NetA2(10)\n",
    "net_a2_dt = NetA2(10)\n",
    "\n",
    "# set same weights and bias to each layer of each network (except for cov1 of net_a1_dt)\n",
    "net_a2_ht.load_state_dict(net_a2_hf.state_dict())\n",
    "net_a2_dt.load_state_dict(net_a2_hf.state_dict())\n",
    "\n",
    "#set conv1 initialization\n",
    "net_a2_hf.conv1.load_state_dict(net_a1_hf.conv1.state_dict())\n",
    "net_a2_ht.conv1.load_state_dict(net_a1_hf.conv1.state_dict())\n",
    "net_a2_dt.conv1.load_state_dict(net_a1_dt.conv1.state_dict())\n",
    "\n",
    "#save weights and bias of nat_a1_h* and net_a1_dt\n",
    "torch.save({'initialization': net_a1_hf.state_dict()}, 'NetA2H+_init.pt')\n",
    "torch.save({'initialization': net_a1_dt.state_dict()}, 'NetA2DT_init.pt')\n",
    "\n",
    "\n",
    "# print weights and bias\n",
    "print(\"Net_A1_HF: \\n \\t\", net_a2_hf.state_dict())\n",
    "print(\"Net_A1_HT: \\n \\t\", net_a2_ht.state_dict())\n",
    "print(\"Net_A1_DT: \\n \\t\", net_a2_dt.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:43:11.856906Z",
     "start_time": "2024-06-12T19:43:11.803082Z"
    }
   },
   "id": "5945b11a44c08847",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preliminary Analysys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e527a7ee28f832"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_A1: \n",
      " \t|W_{conv_a1_hf} - W_{conv_a1_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear_a1_hf} - W_{linear_a1_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear_a1_hf} - W_{linear_a1_dt}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      "\n",
      "Net_A2: \n",
      " \t|W_{conv1_a2_hf} - W_{conv1_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{conv2_a2_hf} - W_{conv2_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear1_a2_hf} - W_{linear1_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear1_a2_hf} - W_{linear1_a2_dt}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear2_a2_hf} - W_{linear2_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear2_a2_hf} - W_{linear2_a2_dt}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear3_a2_hf} - W_{linear3_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{linear3_a2_hf} - W_{linear3_a2_dt}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      "\n",
      "Net_A1 Vs Net_A2: \n",
      " \t|W_{conv1_a1_hf} - W_{conv1_a2_hf}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{conv1_a1_ht} - W_{conv2_a2_ht}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n",
      " \t|W_{conv1_a1_dt} - W_{conv2_a2_dt}| = tensor(0., grad_fn=<LinalgVectorNormBackward0>) \n"
     ]
    }
   ],
   "source": [
    "print( \"Net_A1: \\n\",\n",
    "       \"\\t|W_{conv_a1_hf} - W_{conv_a1_ht}| =\", torch.norm(net_a1_hf.conv1.weight - net_a1_ht.conv1.weight),\"\\n\",\n",
    "      \"\\t|W_{linear_a1_hf} - W_{linear_a1_ht}| =\", torch.norm(net_a1_hf.linear1.weight - net_a1_ht.linear1.weight), \"\\n\",\n",
    "      \"\\t|W_{linear_a1_hf} - W_{linear_a1_dt}| =\", torch.norm(net_a1_hf.linear1.weight - net_a1_dt.linear1.weight), \"\\n\")\n",
    "\n",
    "print( \"Net_A2: \\n\",\n",
    "       \"\\t|W_{conv1_a2_hf} - W_{conv1_a2_ht}| =\", torch.norm(net_a2_hf.conv1.weight - net_a2_ht.conv1.weight),\"\\n\",\n",
    "       \"\\t|W_{conv2_a2_hf} - W_{conv2_a2_ht}| =\", torch.norm(net_a2_hf.conv2.weight - net_a2_ht.conv2.weight),\"\\n\",\n",
    "       \"\\t|W_{linear1_a2_hf} - W_{linear1_a2_ht}| =\", torch.norm(net_a2_hf.linear1.weight - net_a2_ht.linear1.weight), \"\\n\",\n",
    "       \"\\t|W_{linear1_a2_hf} - W_{linear1_a2_dt}| =\", torch.norm(net_a2_hf.linear1.weight - net_a2_dt.linear1.weight), \"\\n\",\n",
    "       \"\\t|W_{linear2_a2_hf} - W_{linear2_a2_ht}| =\", torch.norm(net_a2_hf.linear2.weight - net_a2_ht.linear2.weight), \"\\n\",\n",
    "       \"\\t|W_{linear2_a2_hf} - W_{linear2_a2_dt}| =\", torch.norm(net_a2_hf.linear2.weight - net_a2_dt.linear2.weight), \"\\n\",\n",
    "       \"\\t|W_{linear3_a2_hf} - W_{linear3_a2_ht}| =\", torch.norm(net_a2_hf.linear3.weight - net_a2_ht.linear3.weight), \"\\n\",\n",
    "       \"\\t|W_{linear3_a2_hf} - W_{linear3_a2_dt}| =\", torch.norm(net_a2_hf.linear3.weight - net_a2_dt.linear3.weight), \"\\n\")\n",
    "\n",
    "print( \"Net_A1 Vs Net_A2: \\n\",\n",
    "       \"\\t|W_{conv1_a1_hf} - W_{conv1_a2_hf}| =\", torch.norm(net_a1_hf.conv1.weight - net_a2_hf.conv1.weight),\"\\n\",\n",
    "       \"\\t|W_{conv1_a1_ht} - W_{conv2_a2_ht}| =\", torch.norm(net_a1_ht.conv1.weight - net_a2_ht.conv1.weight),\"\\n\",\n",
    "       \"\\t|W_{conv1_a1_dt} - W_{conv2_a2_dt}| =\", torch.norm(net_a1_dt.conv1.weight - net_a2_dt.conv1.weight),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T19:47:42.033254Z",
     "start_time": "2024-06-12T19:47:42.020303Z"
    }
   },
   "id": "eabba971baa9ea0d",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d9884bc78c276b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data= datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor(),)\n",
    "\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor(),)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T09:55:17.462469Z",
     "start_time": "2024-06-12T09:55:17.414793Z"
    }
   },
   "id": "e8c282a53727943",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 28, 28])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map={\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot',\n",
    "}\n",
    "sample_idx = torch.randint(len(train_data), size = (1,)).item()\n",
    "image, label = train_data[sample_idx]\n",
    "image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T09:41:59.497602Z",
     "start_time": "2024-06-12T09:41:59.489494Z"
    }
   },
   "id": "84fa5b26a60379de",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader= DataLoader(train_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:21:54.586088Z",
     "start_time": "2024-06-12T10:21:54.581101Z"
    }
   },
   "id": "be585d7eb8bcae35",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training/Test Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238fefd45b206a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_loop(device, dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "\n",
    "def test_loop(device, dataloader, model, loss_fn):\n",
    "      size = len(dataloader.dataset)\n",
    "      num_batches = len(dataloader)\n",
    "      test_loss, correct = 0, 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "          X, y = X.to(device), y.to(device)\n",
    "          pred = model(X)\n",
    "          test_loss += loss_fn(pred, y).item()\n",
    "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "      test_loss /= num_batches\n",
    "      correct /= size\n",
    "      print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "      return (100*correct)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b06878e4ef1f642"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79254d3d93db89e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b437c40fa560695f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b905630a2cd56a7f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "134957982e841eca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
